{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!wget https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy as np;\n",
    "import matplotlib.pyplot as plt;\n",
    "from numpy.linalg import inv;\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "x = np.linspace(0,1,100);\n",
    "y = x+1;\n",
    "scaler = StandardScaler();\n",
    "x_scaled = scaler.fit_transform(x.reshape(-1,1));\n",
    "\n",
    "X_b = np.c_[np.ones((len(x_scaled), 1)), x_scaled]\n",
    "theta_ols = inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
    "theta_ols\n",
    "plt.plot(x_scaled, y)\n",
    "#print(x_scaled[0], x_scaled[-1])\n",
    "theta_ols\n",
    "\n",
    "lr = LinearRegression();\n",
    "lr.fit(X_b, y);\n",
    "print(lr.coef_, lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np;\n",
    "import pandas as pd;\n",
    "import scipy;\n",
    "from scipy.linalg import inv;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"prostate.data\",header=0, delimiter=\"\\t\",);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.579818</td>\n",
       "      <td>2.769459</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.430783</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.994252</td>\n",
       "      <td>3.319626</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>2.691243</td>\n",
       "      <td>74</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.203973</td>\n",
       "      <td>3.282789</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.751416</td>\n",
       "      <td>3.432373</td>\n",
       "      <td>62</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.371564</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    lcavol   lweight  age      lbph  svi       lcp  gleason  \\\n",
       "0           1 -0.579818  2.769459   50 -1.386294    0 -1.386294        6   \n",
       "1           2 -0.994252  3.319626   58 -1.386294    0 -1.386294        6   \n",
       "2           3 -0.510826  2.691243   74 -1.386294    0 -1.386294        7   \n",
       "3           4 -1.203973  3.282789   58 -1.386294    0 -1.386294        6   \n",
       "4           5  0.751416  3.432373   62 -1.386294    0 -1.386294        6   \n",
       "\n",
       "   pgg45      lpsa train  \n",
       "0      0 -0.430783     T  \n",
       "1      0 -0.162519     T  \n",
       "2     20 -0.162519     T  \n",
       "3      0 -0.162519     T  \n",
       "4      0  0.371564     T  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.579818</td>\n",
       "      <td>2.769459</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.430783</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.994252</td>\n",
       "      <td>3.319626</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.510826</td>\n",
       "      <td>2.691243</td>\n",
       "      <td>74</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.203973</td>\n",
       "      <td>3.282789</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.751416</td>\n",
       "      <td>3.432373</td>\n",
       "      <td>62</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.371564</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lcavol   lweight  age      lbph  svi       lcp  gleason  pgg45      lpsa  \\\n",
       "0 -0.579818  2.769459   50 -1.386294    0 -1.386294        6      0 -0.430783   \n",
       "1 -0.994252  3.319626   58 -1.386294    0 -1.386294        6      0 -0.162519   \n",
       "2 -0.510826  2.691243   74 -1.386294    0 -1.386294        7     20 -0.162519   \n",
       "3 -1.203973  3.282789   58 -1.386294    0 -1.386294        6      0 -0.162519   \n",
       "4  0.751416  3.432373   62 -1.386294    0 -1.386294        6      0  0.371564   \n",
       "\n",
       "  train  \n",
       "0     T  \n",
       "1     T  \n",
       "2     T  \n",
       "3     T  \n",
       "4     T  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop first column\n",
    "df.drop([df.columns[0]],inplace=True, axis='columns');\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 97 entries, 0 to 96\n",
      "Data columns (total 10 columns):\n",
      "lcavol     97 non-null float64\n",
      "lweight    97 non-null float64\n",
      "age        97 non-null int64\n",
      "lbph       97 non-null float64\n",
      "svi        97 non-null int64\n",
      "lcp        97 non-null float64\n",
      "gleason    97 non-null int64\n",
      "pgg45      97 non-null int64\n",
      "lpsa       97 non-null float64\n",
      "train      97 non-null object\n",
      "dtypes: float64(5), int64(4), object(1)\n",
      "memory usage: 7.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.350010</td>\n",
       "      <td>3.628943</td>\n",
       "      <td>63.865979</td>\n",
       "      <td>0.100356</td>\n",
       "      <td>0.216495</td>\n",
       "      <td>-0.179366</td>\n",
       "      <td>6.752577</td>\n",
       "      <td>24.381443</td>\n",
       "      <td>2.478387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.178625</td>\n",
       "      <td>0.428411</td>\n",
       "      <td>7.445117</td>\n",
       "      <td>1.450807</td>\n",
       "      <td>0.413995</td>\n",
       "      <td>1.398250</td>\n",
       "      <td>0.722134</td>\n",
       "      <td>28.204035</td>\n",
       "      <td>1.154329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.347074</td>\n",
       "      <td>2.374906</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.430783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.512824</td>\n",
       "      <td>3.375880</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.731656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.446919</td>\n",
       "      <td>3.623007</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.300105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.798508</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.591516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.127041</td>\n",
       "      <td>3.876396</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>1.558145</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.178655</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>3.056357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.821004</td>\n",
       "      <td>4.780383</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>2.326302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.904165</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>5.582932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lcavol    lweight        age       lbph        svi        lcp  \\\n",
       "count  97.000000  97.000000  97.000000  97.000000  97.000000  97.000000   \n",
       "mean    1.350010   3.628943  63.865979   0.100356   0.216495  -0.179366   \n",
       "std     1.178625   0.428411   7.445117   1.450807   0.413995   1.398250   \n",
       "min    -1.347074   2.374906  41.000000  -1.386294   0.000000  -1.386294   \n",
       "25%     0.512824   3.375880  60.000000  -1.386294   0.000000  -1.386294   \n",
       "50%     1.446919   3.623007  65.000000   0.300105   0.000000  -0.798508   \n",
       "75%     2.127041   3.876396  68.000000   1.558145   0.000000   1.178655   \n",
       "max     3.821004   4.780383  79.000000   2.326302   1.000000   2.904165   \n",
       "\n",
       "         gleason       pgg45       lpsa  \n",
       "count  97.000000   97.000000  97.000000  \n",
       "mean    6.752577   24.381443   2.478387  \n",
       "std     0.722134   28.204035   1.154329  \n",
       "min     6.000000    0.000000  -0.430783  \n",
       "25%     6.000000    0.000000   1.731656  \n",
       "50%     7.000000   15.000000   2.591516  \n",
       "75%     7.000000   40.000000   3.056357  \n",
       "max     9.000000  100.000000   5.582932  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrrr}\n",
      "\\toprule\n",
      "{} &  lcavol &  lweight &    age &   lbph &    svi &    lcp &  gleason &  pgg45 &   lpsa \\\\\n",
      "\\midrule\n",
      "lcavol  &   1.000 &    0.281 &  0.225 &  0.027 &  0.539 &  0.675 &    0.432 &  0.434 &  0.734 \\\\\n",
      "lweight &   0.281 &    1.000 &  0.348 &  0.442 &  0.155 &  0.165 &    0.057 &  0.107 &  0.433 \\\\\n",
      "age     &   0.225 &    0.348 &  1.000 &  0.350 &  0.118 &  0.128 &    0.269 &  0.276 &  0.170 \\\\\n",
      "lbph    &   0.027 &    0.442 &  0.350 &  1.000 & -0.086 & -0.007 &    0.078 &  0.078 &  0.180 \\\\\n",
      "svi     &   0.539 &    0.155 &  0.118 & -0.086 &  1.000 &  0.673 &    0.320 &  0.458 &  0.566 \\\\\n",
      "lcp     &   0.675 &    0.165 &  0.128 & -0.007 &  0.673 &  1.000 &    0.515 &  0.632 &  0.549 \\\\\n",
      "gleason &   0.432 &    0.057 &  0.269 &  0.078 &  0.320 &  0.515 &    1.000 &  0.752 &  0.369 \\\\\n",
      "pgg45   &   0.434 &    0.107 &  0.276 &  0.078 &  0.458 &  0.632 &    0.752 &  1.000 &  0.422 \\\\\n",
      "lpsa    &   0.734 &    0.433 &  0.170 &  0.180 &  0.566 &  0.549 &    0.369 &  0.422 &  1.000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.corr().round(3).to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data are highly correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lcavol</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.280521</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.027350</td>\n",
       "      <td>0.538845</td>\n",
       "      <td>0.675310</td>\n",
       "      <td>0.432417</td>\n",
       "      <td>0.433652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lweight</th>\n",
       "      <td>0.280521</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.347969</td>\n",
       "      <td>0.442264</td>\n",
       "      <td>0.155385</td>\n",
       "      <td>0.164537</td>\n",
       "      <td>0.056882</td>\n",
       "      <td>0.107354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.347969</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.350186</td>\n",
       "      <td>0.117658</td>\n",
       "      <td>0.127668</td>\n",
       "      <td>0.268892</td>\n",
       "      <td>0.276112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lbph</th>\n",
       "      <td>0.027350</td>\n",
       "      <td>0.442264</td>\n",
       "      <td>0.350186</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.085843</td>\n",
       "      <td>-0.006999</td>\n",
       "      <td>0.077820</td>\n",
       "      <td>0.078460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svi</th>\n",
       "      <td>0.538845</td>\n",
       "      <td>0.155385</td>\n",
       "      <td>0.117658</td>\n",
       "      <td>-0.085843</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.673111</td>\n",
       "      <td>0.320412</td>\n",
       "      <td>0.457648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lcp</th>\n",
       "      <td>0.675310</td>\n",
       "      <td>0.164537</td>\n",
       "      <td>0.127668</td>\n",
       "      <td>-0.006999</td>\n",
       "      <td>0.673111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.514830</td>\n",
       "      <td>0.631528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gleason</th>\n",
       "      <td>0.432417</td>\n",
       "      <td>0.056882</td>\n",
       "      <td>0.268892</td>\n",
       "      <td>0.077820</td>\n",
       "      <td>0.320412</td>\n",
       "      <td>0.514830</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.751905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgg45</th>\n",
       "      <td>0.433652</td>\n",
       "      <td>0.107354</td>\n",
       "      <td>0.276112</td>\n",
       "      <td>0.078460</td>\n",
       "      <td>0.457648</td>\n",
       "      <td>0.631528</td>\n",
       "      <td>0.751905</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           lcavol   lweight       age      lbph       svi       lcp   gleason  \\\n",
       "lcavol   1.000000  0.280521  0.225000  0.027350  0.538845  0.675310  0.432417   \n",
       "lweight  0.280521  1.000000  0.347969  0.442264  0.155385  0.164537  0.056882   \n",
       "age      0.225000  0.347969  1.000000  0.350186  0.117658  0.127668  0.268892   \n",
       "lbph     0.027350  0.442264  0.350186  1.000000 -0.085843 -0.006999  0.077820   \n",
       "svi      0.538845  0.155385  0.117658 -0.085843  1.000000  0.673111  0.320412   \n",
       "lcp      0.675310  0.164537  0.127668 -0.006999  0.673111  1.000000  0.514830   \n",
       "gleason  0.432417  0.056882  0.268892  0.077820  0.320412  0.514830  1.000000   \n",
       "pgg45    0.433652  0.107354  0.276112  0.078460  0.457648  0.631528  0.751905   \n",
       "\n",
       "            pgg45  \n",
       "lcavol   0.433652  \n",
       "lweight  0.107354  \n",
       "age      0.276112  \n",
       "lbph     0.078460  \n",
       "svi      0.457648  \n",
       "lcp      0.631528  \n",
       "gleason  0.751905  \n",
       "pgg45    1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['lpsa'];\n",
    "X = df.drop(['lpsa'],axis=1);\n",
    "X.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled data correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lcavol</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.300232</td>\n",
       "      <td>0.286324</td>\n",
       "      <td>0.063168</td>\n",
       "      <td>0.592949</td>\n",
       "      <td>0.692043</td>\n",
       "      <td>0.426414</td>\n",
       "      <td>0.483161</td>\n",
       "      <td>0.727280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lweight</th>\n",
       "      <td>0.300232</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.316723</td>\n",
       "      <td>0.437042</td>\n",
       "      <td>0.181054</td>\n",
       "      <td>0.156829</td>\n",
       "      <td>0.023558</td>\n",
       "      <td>0.074166</td>\n",
       "      <td>0.598021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.286324</td>\n",
       "      <td>0.316723</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.287346</td>\n",
       "      <td>0.128902</td>\n",
       "      <td>0.172951</td>\n",
       "      <td>0.365915</td>\n",
       "      <td>0.275806</td>\n",
       "      <td>0.345414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lbph</th>\n",
       "      <td>0.063168</td>\n",
       "      <td>0.437042</td>\n",
       "      <td>0.287346</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.139147</td>\n",
       "      <td>-0.088535</td>\n",
       "      <td>0.032992</td>\n",
       "      <td>-0.030404</td>\n",
       "      <td>0.396349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svi</th>\n",
       "      <td>0.592949</td>\n",
       "      <td>0.181054</td>\n",
       "      <td>0.128902</td>\n",
       "      <td>-0.139147</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.671240</td>\n",
       "      <td>0.306875</td>\n",
       "      <td>0.481358</td>\n",
       "      <td>0.451672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lcp</th>\n",
       "      <td>0.692043</td>\n",
       "      <td>0.156829</td>\n",
       "      <td>0.172951</td>\n",
       "      <td>-0.088535</td>\n",
       "      <td>0.671240</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.476437</td>\n",
       "      <td>0.662533</td>\n",
       "      <td>0.434572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gleason</th>\n",
       "      <td>0.426414</td>\n",
       "      <td>0.023558</td>\n",
       "      <td>0.365915</td>\n",
       "      <td>0.032992</td>\n",
       "      <td>0.306875</td>\n",
       "      <td>0.476437</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.757056</td>\n",
       "      <td>0.331608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgg45</th>\n",
       "      <td>0.483161</td>\n",
       "      <td>0.074166</td>\n",
       "      <td>0.275806</td>\n",
       "      <td>-0.030404</td>\n",
       "      <td>0.481358</td>\n",
       "      <td>0.662533</td>\n",
       "      <td>0.757056</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.368055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lpsa</th>\n",
       "      <td>0.727280</td>\n",
       "      <td>0.598021</td>\n",
       "      <td>0.345414</td>\n",
       "      <td>0.396349</td>\n",
       "      <td>0.451672</td>\n",
       "      <td>0.434572</td>\n",
       "      <td>0.331608</td>\n",
       "      <td>0.368055</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           lcavol   lweight       age      lbph       svi       lcp   gleason  \\\n",
       "lcavol   1.000000  0.300232  0.286324  0.063168  0.592949  0.692043  0.426414   \n",
       "lweight  0.300232  1.000000  0.316723  0.437042  0.181054  0.156829  0.023558   \n",
       "age      0.286324  0.316723  1.000000  0.287346  0.128902  0.172951  0.365915   \n",
       "lbph     0.063168  0.437042  0.287346  1.000000 -0.139147 -0.088535  0.032992   \n",
       "svi      0.592949  0.181054  0.128902 -0.139147  1.000000  0.671240  0.306875   \n",
       "lcp      0.692043  0.156829  0.172951 -0.088535  0.671240  1.000000  0.476437   \n",
       "gleason  0.426414  0.023558  0.365915  0.032992  0.306875  0.476437  1.000000   \n",
       "pgg45    0.483161  0.074166  0.275806 -0.030404  0.481358  0.662533  0.757056   \n",
       "lpsa     0.727280  0.598021  0.345414  0.396349  0.451672  0.434572  0.331608   \n",
       "\n",
       "            pgg45      lpsa  \n",
       "lcavol   0.483161  0.727280  \n",
       "lweight  0.074166  0.598021  \n",
       "age      0.275806  0.345414  \n",
       "lbph    -0.030404  0.396349  \n",
       "svi      0.481358  0.451672  \n",
       "lcp      0.662533  0.434572  \n",
       "gleason  0.757056  0.331608  \n",
       "pgg45    1.000000  0.368055  \n",
       "lpsa     0.368055  1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.pipeline import Pipeline\n",
    "std_scaler = StandardScaler();\n",
    "X_train = X[X['train']==\"T\"];\n",
    "y_train = y[X['train']==\"T\"];\n",
    "X_test = X[X['train']==\"F\"];\n",
    "y_test = y[X['train']==\"F\"];\n",
    "X_train = X_train.drop('train',axis=1)\n",
    "#X_scaled = pp.scale(X_train.astype('float')); # this works as the below one\n",
    "X_scaled = std_scaler.fit_transform(X_train.astype('float'));\n",
    "#put together scaled data and output to see the correlation\n",
    "df_scaled = pd.concat([pd.DataFrame(X_scaled), y_train], axis=1, );\n",
    "#-1 because df has still 'train' col\n",
    "df_scaled.columns = df.columns[:-1];\n",
    "df_scaled.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrrr}\n",
      "\\toprule\n",
      "{} &  lcavol &  lweight &    age &   lbph &    svi &    lcp &  gleason &  pgg45 &   lpsa \\\\\n",
      "\\midrule\n",
      "lcavol  &   1.000 &    0.300 &  0.286 &  0.063 &  0.593 &  0.692 &    0.426 &  0.483 &  0.727 \\\\\n",
      "lweight &   0.300 &    1.000 &  0.317 &  0.437 &  0.181 &  0.157 &    0.024 &  0.074 &  0.598 \\\\\n",
      "age     &   0.286 &    0.317 &  1.000 &  0.287 &  0.129 &  0.173 &    0.366 &  0.276 &  0.345 \\\\\n",
      "lbph    &   0.063 &    0.437 &  0.287 &  1.000 & -0.139 & -0.089 &    0.033 & -0.030 &  0.396 \\\\\n",
      "svi     &   0.593 &    0.181 &  0.129 & -0.139 &  1.000 &  0.671 &    0.307 &  0.481 &  0.452 \\\\\n",
      "lcp     &   0.692 &    0.157 &  0.173 & -0.089 &  0.671 &  1.000 &    0.476 &  0.663 &  0.435 \\\\\n",
      "gleason &   0.426 &    0.024 &  0.366 &  0.033 &  0.307 &  0.476 &    1.000 &  0.757 &  0.332 \\\\\n",
      "pgg45   &   0.483 &    0.074 &  0.276 & -0.030 &  0.481 &  0.663 &    0.757 &  1.000 &  0.368 \\\\\n",
      "lpsa    &   0.727 &    0.598 &  0.345 &  0.396 &  0.452 &  0.435 &    0.332 &  0.368 &  1.000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_scaled.corr().round(3).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.pipeline import Pipeline\n",
    "std_scaler = StandardScaler();\n",
    "X_train = X[X['train']==\"T\"];\n",
    "y_train = y[X['train']==\"T\"];\n",
    "X_test = X[X['train'] ==\"F\"];\n",
    "y_test = y[X['train'] ==\"F\"];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.30832816e-17 -4.97114787e-18 -8.34324318e-16  6.62819716e-18\n",
      "  3.97691830e-17 -4.30832816e-17  4.92143639e-16 -3.31409858e-17]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fra/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "#X_train = X;\n",
    "#y_train = y;\n",
    "X_train.drop(['train'], axis=1, inplace=True)\n",
    "#del X, y\n",
    "#### We assume data have been already shuffled.\n",
    "#X_train.head()\n",
    "X_scaled = pp.scale(X_train.astype('float'));\n",
    "print(X_scaled.mean(axis=0))\n",
    "print(X_scaled.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          lcavol    lweight        age       lbph        svi        lcp  \\\n",
      "count  67.000000  67.000000  67.000000  67.000000  67.000000  67.000000   \n",
      "mean    1.313492   3.626108  64.746269   0.071440   0.223881  -0.214203   \n",
      "std     1.242590   0.476601   7.502208   1.463655   0.419989   1.400735   \n",
      "min    -1.347074   2.374906  41.000000  -1.386294   0.000000  -1.386294   \n",
      "25%     0.488279   3.330360  61.000000  -1.386294   0.000000  -1.386294   \n",
      "50%     1.467874   3.598681  65.000000  -0.051293   0.000000  -0.798508   \n",
      "75%     2.349065   3.883610  69.000000   1.547506   0.000000   0.994793   \n",
      "max     3.821004   4.780383  79.000000   2.326302   1.000000   2.656757   \n",
      "\n",
      "         gleason       pgg45  \n",
      "count  67.000000   67.000000  \n",
      "mean    6.731343   26.268657  \n",
      "std     0.708864   29.301764  \n",
      "min     6.000000    0.000000  \n",
      "25%     6.000000    0.000000  \n",
      "50%     7.000000   15.000000  \n",
      "75%     7.000000   50.000000  \n",
      "max     9.000000  100.000000  \n",
      "                  0             1             2             3             4  \\\n",
      "count  6.700000e+01  6.700000e+01  6.700000e+01  6.700000e+01  6.700000e+01   \n",
      "mean   9.610886e-17 -7.125312e-17 -8.078115e-16  2.651279e-17 -2.121023e-16   \n",
      "std    1.007547e+00  1.007547e+00  1.007547e+00  1.007547e+00  1.007547e+00   \n",
      "min   -2.157304e+00 -2.645075e+00 -3.189126e+00 -1.003472e+00 -5.370862e-01   \n",
      "25%   -6.691190e-01 -6.252199e-01 -5.031242e-01 -1.003472e+00 -5.370862e-01   \n",
      "50%    1.251804e-01 -5.798078e-02  3.407614e-02 -8.448679e-02 -5.370862e-01   \n",
      "75%    8.396889e-01  5.443671e-01  5.712765e-01  1.016091e+00 -5.370862e-01   \n",
      "max    2.033202e+00  2.440170e+00  1.914277e+00  1.552196e+00  1.861899e+00   \n",
      "\n",
      "                  5             6             7  \n",
      "count  6.700000e+01  6.700000e+01  6.700000e+01  \n",
      "mean   1.955318e-16  6.114512e-16  5.965377e-17  \n",
      "std    1.007547e+00  1.007547e+00  1.007547e+00  \n",
      "min   -8.430840e-01 -1.039499e+00 -9.032532e-01  \n",
      "25%   -8.430840e-01 -1.039499e+00 -9.032532e-01  \n",
      "50%   -4.202897e-01  3.818568e-01 -3.874751e-01  \n",
      "75%    8.696292e-01  3.818568e-01  8.160072e-01  \n",
      "max    2.065078e+00  3.224568e+00  2.535268e+00  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 67 entries, 0 to 95\n",
      "Data columns (total 8 columns):\n",
      "lcavol     67 non-null float64\n",
      "lweight    67 non-null float64\n",
      "age        67 non-null int64\n",
      "lbph       67 non-null float64\n",
      "svi        67 non-null int64\n",
      "lcp        67 non-null float64\n",
      "gleason    67 non-null int64\n",
      "pgg45      67 non-null int64\n",
      "dtypes: float64(4), int64(4)\n",
      "memory usage: 4.7 KB\n"
     ]
    }
   ],
   "source": [
    "print(X_train.describe());\n",
    "print(pd.DataFrame(X_scaled).describe());\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.30832816e-17 -4.97114787e-18 -8.34324318e-16  6.62819716e-18\n",
      "  3.97691830e-17 -4.30832816e-17  4.92143639e-16 -3.31409858e-17]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "X_scaled = std_scaler.fit_transform(X_train.astype(float));\n",
    "print(np.mean(X_scaled, axis=0));\n",
    "print(np.std(X_scaled, axis=0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lcavol</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.300232</td>\n",
       "      <td>0.286324</td>\n",
       "      <td>0.063168</td>\n",
       "      <td>0.592949</td>\n",
       "      <td>0.692043</td>\n",
       "      <td>0.426414</td>\n",
       "      <td>0.483161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lweight</th>\n",
       "      <td>0.300232</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.316723</td>\n",
       "      <td>0.437042</td>\n",
       "      <td>0.181054</td>\n",
       "      <td>0.156829</td>\n",
       "      <td>0.023558</td>\n",
       "      <td>0.074166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.286324</td>\n",
       "      <td>0.316723</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.287346</td>\n",
       "      <td>0.128902</td>\n",
       "      <td>0.172951</td>\n",
       "      <td>0.365915</td>\n",
       "      <td>0.275806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lbph</th>\n",
       "      <td>0.063168</td>\n",
       "      <td>0.437042</td>\n",
       "      <td>0.287346</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.139147</td>\n",
       "      <td>-0.088535</td>\n",
       "      <td>0.032992</td>\n",
       "      <td>-0.030404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svi</th>\n",
       "      <td>0.592949</td>\n",
       "      <td>0.181054</td>\n",
       "      <td>0.128902</td>\n",
       "      <td>-0.139147</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.671240</td>\n",
       "      <td>0.306875</td>\n",
       "      <td>0.481358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lcp</th>\n",
       "      <td>0.692043</td>\n",
       "      <td>0.156829</td>\n",
       "      <td>0.172951</td>\n",
       "      <td>-0.088535</td>\n",
       "      <td>0.671240</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.476437</td>\n",
       "      <td>0.662533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gleason</th>\n",
       "      <td>0.426414</td>\n",
       "      <td>0.023558</td>\n",
       "      <td>0.365915</td>\n",
       "      <td>0.032992</td>\n",
       "      <td>0.306875</td>\n",
       "      <td>0.476437</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.757056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgg45</th>\n",
       "      <td>0.483161</td>\n",
       "      <td>0.074166</td>\n",
       "      <td>0.275806</td>\n",
       "      <td>-0.030404</td>\n",
       "      <td>0.481358</td>\n",
       "      <td>0.662533</td>\n",
       "      <td>0.757056</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           lcavol   lweight       age      lbph       svi       lcp   gleason  \\\n",
       "lcavol   1.000000  0.300232  0.286324  0.063168  0.592949  0.692043  0.426414   \n",
       "lweight  0.300232  1.000000  0.316723  0.437042  0.181054  0.156829  0.023558   \n",
       "age      0.286324  0.316723  1.000000  0.287346  0.128902  0.172951  0.365915   \n",
       "lbph     0.063168  0.437042  0.287346  1.000000 -0.139147 -0.088535  0.032992   \n",
       "svi      0.592949  0.181054  0.128902 -0.139147  1.000000  0.671240  0.306875   \n",
       "lcp      0.692043  0.156829  0.172951 -0.088535  0.671240  1.000000  0.476437   \n",
       "gleason  0.426414  0.023558  0.365915  0.032992  0.306875  0.476437  1.000000   \n",
       "pgg45    0.483161  0.074166  0.275806 -0.030404  0.481358  0.662533  0.757056   \n",
       "\n",
       "            pgg45  \n",
       "lcavol   0.483161  \n",
       "lweight  0.074166  \n",
       "age      0.275806  \n",
       "lbph    -0.030404  \n",
       "svi      0.481358  \n",
       "lcp      0.662533  \n",
       "gleason  0.757056  \n",
       "pgg45    1.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_scaled, columns=X_train.columns).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lcavol', 'lweight', 'age', 'lbph', 'svi', 'lcp', 'gleason', 'pgg45'], dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.08701959, 0.13250132, 0.10558798, 0.10135462, 0.1023518 ,\n",
       "        0.12445059, 0.15364444, 0.14151003, 0.1583969 ]),\n",
       " array([28.18152744,  5.36629046,  2.75078939, -1.39590898,  2.05584563,\n",
       "         2.46925518, -1.86691264, -0.14668121,  1.73783972]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "#X_b = np.c_[np.ones((len(X_scaled), 1)), X_scaled]\n",
    "\n",
    "\n",
    "class CustomLinearRegression(LinearRegression):\n",
    "    def __init__(self):\n",
    "        super(CustomLinearRegression, self).__init__();\n",
    "    def z_scores(self, y, X, bias=False):\n",
    "        p = len(self.coef_);\n",
    "        if (bias):\n",
    "            y_pred = self.predict(X[:,1:]);\n",
    "            X_with_bias = X;\n",
    "        else:\n",
    "            y_pred = self.predict(X);\n",
    "            X_with_bias = np.c_[np.ones((X.shape[0], 1)), X];\n",
    "        sigma_hat_sq = np.sum(np.square(y_train-y_pred))/(len(y_train)-p-1);\n",
    "        std_err  = np.sqrt(np.diag(inv(X_with_bias.T.dot(X_with_bias)))*sigma_hat_sq);\n",
    "        z_scores = np.multiply(np.append(self.intercept_, self.coef_), 1/std_err);\n",
    "        return std_err, z_scores;\n",
    "    def get_intercept_coef(self):\n",
    "        return np.append(self.intercept_, self.coef_);\n",
    "lr = CustomLinearRegression();\n",
    "lr.fit( X_scaled, y_train);\n",
    "lr.z_scores(y_train, X_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.71104059,  0.29045029, -0.14148182,  0.21041951,  0.30730025,\n",
       "        -0.28684075, -0.02075686,  0.27526843]), 2.4523450850746267)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_, lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.00000000e+00  4.30832816e-17 -4.97114787e-18 -8.34324318e-16\n",
      "  6.62819716e-18  3.97691830e-17 -4.30832816e-17  4.92143639e-16\n",
      " -3.31409858e-17]\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import inv;\n",
    "X_b = np.c_[np.ones((len(X_scaled), 1)), X_scaled];\n",
    "print(np.mean(X_b, axis=0));\n",
    "theta = inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.45234509,  0.71104059,  0.29045029, -0.14148182,  0.21041951,\n",
       "        0.30730025, -0.28684075, -0.02075686,  0.27526843])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice that the stochastic gradient coefficients are slightly different "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrrrrr}\n",
      "\\toprule\n",
      " intercept &  lcavol &  lweight &    age &  lbph &    svi &    lcp &  gleason &  pgg45 \\\\\n",
      "\\midrule\n",
      "     2.452 &   0.711 &     0.29 & -0.141 &  0.21 &  0.307 & -0.287 &   -0.021 &  0.275 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_iter = 1000;\n",
    "np.random.seed(42);\n",
    "eta = 0.1\n",
    "theta_gd = np.random.randn(X_b.shape[1],1);\n",
    "for ii in range(n_iter):\n",
    "    gradient =  -2/len(X_b)*X_b.T.dot(np.c_[y_train] - X_b.dot(theta_gd));\n",
    "    theta_gd = theta_gd - eta*gradient;\n",
    "    \n",
    "print(pd.DataFrame(theta_gd.T, \n",
    "        columns=np.concatenate((np.array([\"intercept\"]), X_train.columns)))\n",
    "      .round(3).to_latex(index=False));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_scaled);\n",
    "y_pred_man = X_b.dot(theta);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **residual sum of squares (RSS)** and **Mean square error(MSE)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.43919976805833433, 0.43919976805833433)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error;\n",
    "np.sum(np.square(y_train-y_pred))/len(y_pred), mean_squared_error(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.43919976805833433, 0.43919976805833433)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error;\n",
    "np.sum(np.square(y_train-y_pred_man))/len(y_pred), mean_squared_error(y_train, y_pred_man)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Std. error</th>\n",
       "      <th>$Z$ score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>2.45</td>\n",
       "      <td>0.09</td>\n",
       "      <td>28.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lcavol</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.13</td>\n",
       "      <td>5.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lweight</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lbph</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svi</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lcp</th>\n",
       "      <td>-0.29</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-1.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gleason</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgg45</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Coefficient  Std. error  $Z$ score\n",
       "intercept         2.45        0.09      28.18\n",
       "lcavol            0.71        0.13       5.37\n",
       "lweight           0.29        0.11       2.75\n",
       "age              -0.14        0.10      -1.40\n",
       "lbph              0.21        0.10       2.06\n",
       "svi               0.31        0.12       2.47\n",
       "lcp              -0.29        0.15      -1.87\n",
       "gleason          -0.02        0.14      -0.15\n",
       "pgg45             0.28        0.16       1.74"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apparently, scikit does not support statistical inference delibarately\n",
    "def Z_score(y_train, theta, X_with_bias):\n",
    "    p = X_with_bias.shape[1]-1;\n",
    "    y_pred = X_with_bias.dot(theta);\n",
    "    sigma_hat_sq = np.sum(np.square(y_train-y_pred))/(len(y_train)-p-1);\n",
    "    std_err  = np.sqrt(np.diag(inv(X_with_bias.T.dot(X_with_bias)))*sigma_hat_sq);\n",
    "    z_scores = np.multiply(theta, 1/std_err);\n",
    "    return z_scores, std_err;\n",
    "\n",
    "z_scores, std_err = Z_score(y_train, theta, X_b);\n",
    "\n",
    "pd.DataFrame({\"Coefficient\": theta, \"Std. error\" : std_err,\n",
    "              r\"$Z$ score\" : z_scores.ravel(),},\n",
    "             index=pd.Index([\"intercept\"]).append(X_train.columns)\n",
    "            ).round(2).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the extended linear Regression class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Std. error</th>\n",
       "      <th>$Z$ score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>2.45</td>\n",
       "      <td>0.09</td>\n",
       "      <td>28.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lcavol</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.13</td>\n",
       "      <td>5.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lweight</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lbph</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svi</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lcp</th>\n",
       "      <td>-0.29</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-1.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gleason</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgg45</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Coefficient  Std. error  $Z$ score\n",
       "intercept         2.45        0.09      28.18\n",
       "lcavol            0.71        0.13       5.37\n",
       "lweight           0.29        0.11       2.75\n",
       "age              -0.14        0.10      -1.40\n",
       "lbph              0.21        0.10       2.06\n",
       "svi               0.31        0.12       2.47\n",
       "lcp              -0.29        0.15      -1.87\n",
       "gleason          -0.02        0.14      -0.15\n",
       "pgg45             0.28        0.16       1.74"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_err_lr, z_scores_lr = lr.z_scores(y_train, X_scaled);\n",
    "pd.DataFrame({\"Coefficient\": lr.get_intercept_coef(), \"Std. error\" : std_err_lr,\n",
    "              r\"$Z$ score\" : z_scores_lr},\n",
    "             index=pd.Index([\"intercept\"]).append(X_train.columns)\n",
    "            ).round(2).head(len(lr.coef_)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "{} &  Coefficient &  Std. error &  \\$Z\\$ score \\\\\n",
      "\\midrule\n",
      "intercept &         2.45 &        0.09 &      28.18 \\\\\n",
      "lcavol    &         0.71 &        0.13 &       5.37 \\\\\n",
      "lweight   &         0.29 &        0.11 &       2.75 \\\\\n",
      "age       &        -0.14 &        0.10 &      -1.40 \\\\\n",
      "lbph      &         0.21 &        0.10 &       2.06 \\\\\n",
      "svi       &         0.31 &        0.12 &       2.47 \\\\\n",
      "lcp       &        -0.29 &        0.15 &      -1.87 \\\\\n",
      "gleason   &        -0.02 &        0.14 &      -0.15 \\\\\n",
      "pgg45     &         0.28 &        0.16 &       1.74 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame({\"Coefficient\": lr.get_intercept_coef(), \"Std. error\" : std_err_lr,\n",
    "              \"$Z$ score\" : z_scores_lr},\n",
    "             index=pd.Index([\"intercept\"]).append(X_train.columns)\n",
    "            ).round(2).to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best subset selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn does not support\n",
    "import itertools;\n",
    "\n",
    "#intercept only\n",
    "X_small = np.copy(X_b[:,0]).reshape(-1,1); #np.ones\n",
    "b_man  = scipy.linalg.inv(X_small.T.dot(X_small)).dot(X_small.T.dot(y_train));\n",
    "lr = CustomLinearRegression();\n",
    "lr.fit(X_small, y_train);\n",
    "y_pred_sk  = lr.predict(X_small);\n",
    "y_pred_man = X_small.dot(b_man);\n",
    "rss_sk  = np.sum(np.square(y_train-y_pred_sk));\n",
    "rss_man = np.sum(np.square(y_train-y_pred_man.reshape(y_train.shape)));\n",
    "num_features = X_b.shape[1]-1;\n",
    "best_models = {num_features : dict()};\n",
    "best_subset = dict();\n",
    "best_subset['names']      = [\"intercept\",];\n",
    "best_subset['indexes']    = [0]; #wrt X_with_bias_coeffs\n",
    "best_subset['coeffs']     = b_man;\n",
    "best_subset['err']        = rss_man;\n",
    "errors = {\"features\":\"intercept\", \"errors\":rss_man};\n",
    "best_subset['all_errors'] = errors;\n",
    "best_subset['skl_model']  = lr;\n",
    "best_models[0] = best_subset;\n",
    "best_models[\"error_sequence\"] = list();\n",
    "best_models[\"error_sequence\"].append(best_subset['err']);\n",
    "\n",
    "for num_features in np.arange(1,len(X_train.columns)+1):\n",
    "    err = np.infty;\n",
    "    best_subset = dict();\n",
    "    errors = {\"features\":list(), \"errors\":list()};\n",
    "    \n",
    "    for ff in list(itertools.combinations(X_train.columns, num_features)):\n",
    "        #+1 because it will be used with the row of ones\n",
    "        idx = [X_train.columns.get_loc(ii)+1 for ii in ff]; \n",
    "        idx.insert(0,0);\n",
    "        X_small = X_b[:,idx];\n",
    "\n",
    "        b_man  = inv(X_small.T.dot(X_small)).dot(X_small.T).dot(y_train);\n",
    "        lr = LinearRegression();\n",
    "        #print(X_small.shape)\n",
    "        lr.fit(X_small[:,1:], y_train);\n",
    "        y_pred_sk  = lr.predict(X_small[:,1:]);\n",
    "        y_pred_man = X_small.dot(b_man);\n",
    "        rss_sk  = np.sum(np.square(y_train-y_pred_sk));\n",
    "        rss_man = np.sum(np.square(y_train-y_pred_man));\n",
    "        \n",
    "        errors[\"features\"].append(ff);\n",
    "        errors['errors'].append(rss_man);\n",
    "        if rss_man < err:\n",
    "            err = rss_man;\n",
    "            best_subset['names']   = ff;\n",
    "            best_subset['indexes'] = idx; #wrt X_with_bias_coeffs\n",
    "            best_subset['coeffs']  = b_man;\n",
    "            best_subset['err']     = rss_man/len(y_train);\n",
    "            best_subset['all_errors'] = errors;\n",
    "            best_subset['skl_model'] = lr;\n",
    "            \n",
    "      \n",
    "    best_models[\"error_sequence\"].append(best_subset['err']);\n",
    "    best_models[num_features] = best_subset;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'names': ('lcavol', 'lweight', 'age', 'lbph', 'svi', 'lcp', 'pgg45'),\n",
       " 'indexes': [0, 1, 2, 3, 4, 5, 6, 8],\n",
       " 'coeffs': array([ 2.45234509,  0.70781828,  0.29290477, -0.1450474 ,  0.20980704,\n",
       "         0.30920631, -0.28557946,  0.26014081]),\n",
       " 'err': 0.4393626913047325,\n",
       " 'all_errors': {'features': [('lcavol',\n",
       "    'lweight',\n",
       "    'age',\n",
       "    'lbph',\n",
       "    'svi',\n",
       "    'lcp',\n",
       "    'gleason'),\n",
       "   ('lcavol', 'lweight', 'age', 'lbph', 'svi', 'lcp', 'pgg45'),\n",
       "   ('lcavol', 'lweight', 'age', 'lbph', 'svi', 'gleason', 'pgg45'),\n",
       "   ('lcavol', 'lweight', 'age', 'lbph', 'lcp', 'gleason', 'pgg45'),\n",
       "   ('lcavol', 'lweight', 'age', 'svi', 'lcp', 'gleason', 'pgg45'),\n",
       "   ('lcavol', 'lweight', 'lbph', 'svi', 'lcp', 'gleason', 'pgg45'),\n",
       "   ('lcavol', 'age', 'lbph', 'svi', 'lcp', 'gleason', 'pgg45'),\n",
       "   ('lweight', 'age', 'lbph', 'svi', 'lcp', 'gleason', 'pgg45')],\n",
       "  'errors': [30.958629941880634,\n",
       "   29.437300317417076,\n",
       "   31.194688345903852,\n",
       "   32.51981848057305,\n",
       "   31.57070601748839,\n",
       "   30.414990170034596,\n",
       "   33.26543290315886,\n",
       "   44.036621512704976]},\n",
       " 'skl_model': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "          normalize=False)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "import itertools;\n",
    "from sklearn.pipeline import Pipeline;\n",
    "from sklearn.preprocessing import StandardScaler;\n",
    "from sklearn.base import clone;\n",
    "from sklearn.metrics import mean_squared_error;\n",
    "\n",
    "class error_sequence:\n",
    "    def __init__(self, errors=tuple(), sequence=tuple()):\n",
    "        self.errors = list(errors);\n",
    "        self.names  = list(sequence);\n",
    "    \n",
    "    def printErrs(self):\n",
    "        for err, el in zip(self.errors, self.names):\n",
    "            print(str(el) + \": \" + str(err));\n",
    "    \n",
    "    def addNewElement(self, names : tuple, val: float, idx : tuple):\n",
    "        ids = tuple();\n",
    "        if names:\n",
    "            ids = tuple([names[el] for el in idx]);\n",
    "        else:\n",
    "            ids = idx;\n",
    "        self.names.append(ids);\n",
    "        self.errors.append(val,);\n",
    "\n",
    "class best_submodel_abstract:\n",
    "    def __init__(self):\n",
    "        self._standardInit();\n",
    "        #later let user choose type\n",
    "        self.pipeline = Pipeline([\n",
    "                ('Scaler', StandardScaler()), \n",
    "                ('LinearRegression',  CustomLinearRegression())]);  \n",
    "    \n",
    "    def get_scaler(self):\n",
    "        return self.pipeline.named_steps['Scaler'];\n",
    "    def get_model(self):\n",
    "        return self.pipeline.named_steps['LinearRegression'];\n",
    "        \n",
    "        \n",
    "    def _standardInit(self):\n",
    "        self.num_features    = None;\n",
    "        self.feature_names   = None;\n",
    "        self.best_subset_idx = None; #wrt X_with_bias_coeffs\n",
    "        self.best_error      = None;\n",
    "        self.all_errors      = error_sequence();\n",
    "        self.skl_model       = None;\n",
    "        self.column_names    = None;\n",
    "        \n",
    "    def _removeBias(self, X, num_features, isItwithoutBias=True):\n",
    "        self.num_features = num_features;\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            self.column_names = list(X.columns);\n",
    "            X = X.values;\n",
    "            \n",
    "        if (not isItwithoutBias):\n",
    "            # scikit will be used and LinearRegression does not want the column of 1s\n",
    "            print(\"removing bias\");\n",
    "            X_small = X[:,1:];\n",
    "        else:\n",
    "            X_small = X;\n",
    "        return X_small;\n",
    "    \n",
    "    def fit(self, X, y,num_features, isItwithoutBias=True):\n",
    "        return;\n",
    "    \n",
    "    def _update_best_model(self, pipeline, subset, mse, col_names):\n",
    "        self.pipeline        = pipeline;\n",
    "        self.best_subset     = subset;\n",
    "        self.best_subset_idx = subset; #wrt X_with_bias_coeffs\n",
    "        self.best_error      = mse;\n",
    "        self.model           = self.get_model();\n",
    "        self.scaler          = self.get_scaler();\n",
    "        if col_names:\n",
    "            self.feature_names = col_names;\n",
    "        return \n",
    "    \n",
    "    def fit1Step(self, X_no_bias, y, idx:tuple)->(Pipeline, float):\n",
    "        # copy to have the same type instead of declaring\n",
    "        X_small = X_no_bias[:,idx]; \n",
    "\n",
    "        temp_pipe = clone(self.pipeline); \n",
    "        temp_pipe.fit(X_small, y); #probably separate scaler for transform\n",
    "        y_pred_sk  = temp_pipe.predict(X_small);\n",
    "        mse_sk     = mean_squared_error(y_train,y_pred_sk);\n",
    "        return temp_pipe, mse_sk;\n",
    "\n",
    "class best_submodel_sk(best_submodel_abstract):\n",
    "    def __init__(self):\n",
    "        super(best_submodel_sk, self).__init__();\n",
    "        \n",
    "    def fit(self, X, y, num_features, isItwithoutBias=True):\n",
    "        X_no_bias   = self._removeBias(X,num_features, isItwithoutBias);\n",
    "        err = np.infty;\n",
    "        all_idx = [i for i in range(X_no_bias.shape[1])];\n",
    "        errors = error_sequence();\n",
    "        if num_features==0:\n",
    "            temp_pipe, mse_sk = self.fit1Step(np.ones((X_no_bias.shape[0],1)), y, (0,));\n",
    "            errors.addNewElement((\"intercept\",), mse_sk, (0,));\n",
    "            self._update_best_model(temp_pipe, None, mse_sk, tuple(('intercept',)));\n",
    "            return;\n",
    "        elif num_features>X_no_bias.shape[1]:\n",
    "            num_features=X_no_bias.shape[1];\n",
    "        for ff in list(itertools.combinations(all_idx, num_features)):\n",
    "            temp_pipe, mse_sk = self.fit1Step(X_no_bias, y, tuple(ff));\n",
    "            errors.addNewElement(self.column_names, mse_sk, ff);\n",
    "            if mse_sk < err:\n",
    "                err = mse_sk;\n",
    "                if self.column_names:\n",
    "                    names = [\"intercept\"] + [self.column_names[ii] for ii in ff];\n",
    "                self._update_best_model(temp_pipe, ff, mse_sk, tuple(names));\n",
    "        self.all_errors = errors;\n",
    "\n",
    "class AllModels:\n",
    "    def __init__(self):\n",
    "        self.bestModels = dict();\n",
    "        \n",
    "class AllBestModels(AllModels):\n",
    "    def __init__(self):\n",
    "        super(AllBestModels, self).__init__();\n",
    "    def fit(self, X, y, isItwithoutBias=True):\n",
    "        #+1: range ends before the last extreme: if without bias\n",
    "        # one must add 1 to include all features.\n",
    "        # if with bias the +1 is included because the matrix has the intercept\n",
    "        max_num_feat = X.shape[1]+1*int(isItwithoutBias); \n",
    "        for el in range(0,max_num_feat):\n",
    "            l = best_submodel_sk();\n",
    "            l.fit(X, y, el);\n",
    "            self.bestModels[el]=l;\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.45234509, 0.77401717, 0.34927407])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = AllBestModels()\n",
    "a.fit(X_train, y_train);\n",
    "a.bestModels[2].model.get_intercept_coef()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward stepwise selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67, 9)\n"
     ]
    }
   ],
   "source": [
    "#sklearn does not support\n",
    "import itertools;\n",
    "from scipy.linalg import inv\n",
    "\n",
    "\n",
    "print(X_b.shape)\n",
    "#intercept only\n",
    "num_features = X_b.shape[1]-1;\n",
    "X_small = np.copy(X_b[:,0]).reshape(-1,1); #np.ones\n",
    "b_man  = scipy.linalg.inv(X_small.T.dot(X_small)).dot(X_small.T.dot(y_train));\n",
    "lr = LinearRegression();\n",
    "lr.fit(X_small, y_train);\n",
    "y_pred_sk  = lr.predict(X_small);\n",
    "y_pred_man = X_small.dot(b_man);\n",
    "rss_sk  = np.sum(np.square(y_train-y_pred_sk));\n",
    "rss_man = np.sum(np.square(y_train-y_pred_man.reshape(y_train.shape)));\n",
    "best_fw_models = {num_features : dict()};\n",
    "best_fw_subset = dict();\n",
    "best_fw_subset['names']      = [\"intercept\",];\n",
    "best_fw_subset['indexes']    = [0]; #wrt X_with_bias_coeffs\n",
    "best_fw_subset['coeffs']     = b_man;\n",
    "best_fw_subset['err']        = rss_man;\n",
    "best_fw_subset['all_errors'] = [];\n",
    "best_fw_subset['skl_model']  = lr;\n",
    "best_fw_models[0] = best_fw_subset.copy();\n",
    "best_fw_models[\"error_sequence\"] = list();\n",
    "best_fw_models[\"error_sequence\"].append(best_fw_subset['err']);\n",
    "best_fw_subset['indexes'] = [0,];\n",
    "l_feat = list(X_train.columns);\n",
    "for num_features in np.arange(1,len(X_train.columns)+1):\n",
    "    #print(best_fw_subset['coeffs'])\n",
    "    err = np.infty;\n",
    "    errors = {\"features\":list(), \"errors\":list()};\n",
    "    best_fw_subset['names'].append('')\n",
    "    best_fw_subset['indexes'].append(np.infty);\n",
    "    for ff in l_feat:\n",
    "        idx = best_fw_subset['indexes'][:-1];\n",
    "        idx.append(X_train.columns.get_loc(ff)+1);\n",
    "        X_small = X_b[:,idx];\n",
    "        b_man = inv(X_small.T.dot(X_small)).dot(X_small.T).dot(y_train);\n",
    "        lr = LinearRegression();\n",
    "        lr.fit(X_small[:,1:], y_train);\n",
    "        y_pred_sk  = lr.predict(X_small[:,1:]);\n",
    "        y_pred_man = X_small.dot(b_man);\n",
    "\n",
    "        rss_sk  = np.sum(np.square(y_train-y_pred_sk));\n",
    "        rss_man = np.sum(np.square(y_train-y_pred_man));\n",
    "        errors[\"features\"].append(ff);\n",
    "        errors['errors'].append(rss_man);\n",
    "        if rss_man < err:\n",
    "            err = rss_man;\n",
    "            best_fw_subset['names'][-1]   = ff;\n",
    "            best_fw_subset['indexes'][-1] = idx[-1]; #wrt X_with_bias_coeffs\n",
    "            best_fw_subset['coeffs']      = b_man.copy();\n",
    "            best_fw_subset['err']         = rss_man;\n",
    "            best_fw_subset['all_errors']  = errors;\n",
    "            best_fw_subset['skl_model']   = lr;\n",
    "\n",
    "    l_feat.remove(best_fw_subset['names'][-1]);\n",
    "    best_fw_models[\"error_sequence\"].append(best_fw_subset['err']);\n",
    "    best_fw_models[num_features] = best_fw_subset.copy();\n",
    "    #print(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.45234509, 0.64128976, 0.34852683, 0.22422118])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_fw_models[3][\"coeffs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orthogonal dependent stepwise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67, 9)\n",
      "(67, 1)\n"
     ]
    }
   ],
   "source": [
    "#sklearn does not support\n",
    "from scipy.linalg import inv\n",
    "\n",
    "num_features = X_b.shape[1]-1;\n",
    "print(X_b.shape)\n",
    "#intercept only\n",
    "X_small = np.copy(X_b[:,0]).reshape(-1,1); #np.ones\n",
    "b_man  = scipy.linalg.inv(X_small.T.dot(X_small)).dot(X_small.T.dot(y_train));\n",
    "lr = LinearRegression();\n",
    "lr.fit(X_small, y_train);\n",
    "y_pred_sk  = lr.predict(X_small);\n",
    "print(X_small.shape)\n",
    "y_pred_man = X_small.dot(b_man);\n",
    "rss_sk  = np.sum(np.square(y_train-y_pred_sk));\n",
    "rss_man = np.sum(np.square(y_train-y_pred_man.reshape(y_train.shape)));\n",
    "best_fw_orth_dep_models = {num_features : dict()};\n",
    "best_fw_orth_dep_subset = dict();\n",
    "best_fw_orth_dep_subset['names']      = [\"intercept\",];\n",
    "best_fw_orth_dep_subset['indexes']    = [0]; #wrt X_with_bias_coeffs\n",
    "best_fw_orth_dep_subset['coeffs']     = b_man;\n",
    "best_fw_orth_dep_subset['err']        = rss_man;\n",
    "best_fw_orth_dep_subset['all_errors'] = [];\n",
    "best_fw_orth_dep_subset['skl_model']  = lr;\n",
    "best_fw_orth_dep_models[0] = best_fw_orth_dep_subset.copy();\n",
    "best_fw_orth_dep_models[\"error_sequence\"] = list();\n",
    "best_fw_orth_dep_models[\"error_sequence\"].append(best_fw_orth_dep_subset['err']);\n",
    "best_fw_orth_dep_subset['indexes'] = [0,];\n",
    "l_feat = list(X_train.columns);\n",
    "y_new  = y_train;\n",
    "for num_features in np.arange(1,len(X_train.columns)+1):\n",
    "    err = np.infty;\n",
    "    errors = {\"features\":list(), \"errors\":list()};\n",
    "    best_fw_orth_dep_subset['names'].append('')\n",
    "    best_fw_orth_dep_subset['indexes'].append(np.infty);\n",
    "    for ff in l_feat:\n",
    "        idx = best_fw_orth_dep_subset['indexes'][:-1];\n",
    "        idx.append(X_train.columns.get_loc(ff)+1);\n",
    "        X_small = X_b[:,idx];\n",
    "        b_man = inv(X_small.T.dot(X_small)).dot(X_small.T).dot(y_train);\n",
    "        lr = LinearRegression();\n",
    "        lr.fit(X_small[:,1:], y_train);\n",
    "        y_pred_sk  = lr.predict(X_small[:,1:]);\n",
    "        y_pred_man = X_small.dot(b_man);\n",
    "        rss_sk  = np.sum(np.square(y_train-y_pred_sk));\n",
    "        rss_man = np.sum(np.square(y_train-y_pred_man));\n",
    "        errors[\"features\"].append(ff);\n",
    "        errors['errors'].append(rss_man);\n",
    "        if rss_man < err:\n",
    "            err = rss_man;\n",
    "            #print(best_fw_subset['names'])\n",
    "            best_fw_orth_dep_subset['names'][-1]   = ff;\n",
    "            best_fw_orth_dep_subset['indexes'][-1] = idx[-1]; #wrt X_with_bias_coeffs\n",
    "            best_fw_orth_dep_subset['coeffs']      = b_man;\n",
    "            best_fw_orth_dep_subset['err']         = rss_man;\n",
    "            best_fw_orth_dep_subset['all_errors']  = errors;\n",
    "            best_fw_orth_dep_subset['skl_model']   = lr;\n",
    "\n",
    "    #here is the difference from normal forward stepwise\n",
    "    y_new = y_new - y_pred;\n",
    "    l_feat.remove(best_fw_orth_dep_subset['names'][-1]);\n",
    "    best_fw_orth_dep_models[\"error_sequence\"].append(best_fw_orth_dep_subset['err']);\n",
    "    best_fw_orth_dep_models[num_features] = best_fw_orth_dep_subset.copy();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.45234509, 0.64128976, 0.34852683, 0.22422118])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models[3][\"coeffs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QR forward stepwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67, 9)\n",
      "[2.45234509 0.58245277 0.26675877 0.24100319 0.19918756 0.12594814]\n"
     ]
    }
   ],
   "source": [
    "#sklearn does not support\n",
    "from scipy.linalg import inv\n",
    "import scipy.linalg\n",
    "import scipy.linalg\n",
    "\n",
    "print(X_b.shape)\n",
    "\n",
    "num_features = X_b.shape[1]-1;\n",
    "l_feat = list(X_train.columns);\n",
    "y_new  = y_train;\n",
    "\n",
    "q1  = X_b[:,0];\n",
    "q1  = (q1/scipy.linalg.norm(q1));\n",
    "q1.reshape(-1,1);\n",
    "r   = q1.dot(X_b[:,0]);\n",
    "Q   = q1.reshape(-1,1);\n",
    "R   = np.array(r).reshape(1,1);\n",
    "y_hat = Q.dot(Q.T).dot(y_train);\n",
    "y_new = y_new-y_hat;\n",
    "rss_man = np.sum(np.square(y_train-y_hat));\n",
    "b_man = np.linalg.inv(R).dot(Q.T).dot(y_train);\n",
    "selected_idx = list();\n",
    "selected_idx.append(0);\n",
    "best_fw_qr_models = {num_features : dict()};\n",
    "best_fw_qr_subset = dict();\n",
    "best_fw_qr_subset['names']          = [\"intercept\",];\n",
    "best_fw_qr_subset['indexes']        = [0]; #wrt X_with_bias_coeffs\n",
    "best_fw_qr_subset['coeffs']         = b_man.copy();\n",
    "best_fw_qr_subset['err']            = rss_man;\n",
    "best_fw_qr_subset['all_errors']     = [];\n",
    "best_fw_qr_subset['skl_model']      = lr;\n",
    "best_fw_qr_subset['indexes']        = [0,];\n",
    "best_fw_qr_models[0]                = best_fw_qr_subset.copy();\n",
    "best_fw_qr_models[\"error_sequence\"] = list();\n",
    "best_fw_qr_models[\"error_sequence\"].append(best_fw_qr_subset['err']);\n",
    "for num_features in np.arange(1,len(X_train.columns)+1):\n",
    "    best_ = -np.infty;\n",
    "    errors = {\"features\":list(), \"errors\":list()};\n",
    "    best_fw_qr_subset['names'].append('');\n",
    "    best_fw_qr_subset['indexes'].append(np.infty);\n",
    "    for ff in l_feat:\n",
    "        idx = X_train.columns.get_loc(ff)+1;\n",
    "        #take the new features\n",
    "        x_k = X_b[:,idx].reshape(-1,1);\n",
    "        #project the new feature onto the feature sapce and take the residual\n",
    "        residual = x_k - Q.dot(Q.T.dot(x_k));#x_k.T.dot(Q).dot(Q.T).T;\n",
    "        #Once normalized the residual becomes a new axis\n",
    "        q_new = residual/scipy.linalg.norm(residual);\n",
    "        # The next feature is the one for which the projection of y onto\n",
    "        # itself has the biggest value.\n",
    "        y_q_prod_sq = np.square(y_new.T.dot(q_new));\n",
    "        #update Q\n",
    "        Q_temp = np.concatenate((Q,q_new), axis=1);\n",
    "        #expand R by adding a row of 0 at the end\n",
    "        R_temp = np.concatenate((R,np.zeros((1,R.shape[1]))), axis=0);\n",
    "        #expand R by adding a column at the end with new projection\n",
    "        R_temp = np.concatenate((R_temp, x_k.T.dot(Q_temp).T), axis =1)\n",
    "        y_hat = Q_temp.dot(Q_temp.T).dot(y_train);\n",
    "        rss_man = np.sum(np.square(y_train-y_hat));\n",
    "        errors[\"features\"].append(ff);\n",
    "        errors['errors'].append(rss_man);\n",
    "        if (y_q_prod_sq> best_):\n",
    "            q_best = q_new;\n",
    "            r_best = residual;\n",
    "            best_ = y_q_prod_sq;\n",
    "            best_ff = ff;\n",
    "            best_fw_qr_subset['err'] = rss_man;\n",
    "            x_best = x_k;\n",
    "\n",
    "    Q = np.concatenate((Q,q_best), axis=1);\n",
    "    R = np.concatenate((R,np.zeros((1,R.shape[1]))), axis=0);\n",
    "#    R = np.concatenate((R,x_k.T.dot(Q)), axis =1)\n",
    "    R = np.concatenate((R,Q.T.dot(x_best)), axis=1)\n",
    "    #here is the difference from normal forward stepwise\n",
    "    y_hat = Q.dot(Q.T).dot(y_train);\n",
    "    y_new = y_new - y_hat;#\n",
    "    b_man = np.linalg.inv(R.T.dot(R)).dot(R.T).dot(Q.T).dot(y_train);\n",
    "    best_fw_qr_subset['names'][-1]   = best_ff;\n",
    "    best_fw_qr_subset['indexes'][-1] = idx; #wrt X_with_bias_coeffs\n",
    "    best_fw_qr_subset['coeffs']      = b_man.copy();\n",
    "    best_fw_qr_subset['all_errors']  = errors;\n",
    "    l_feat.remove(best_ff);\n",
    "    best_fw_qr_models[\"error_sequence\"].append(best_fw_qr_subset['err']);\n",
    "    best_fw_qr_models[num_features] = best_fw_qr_subset.copy();\n",
    "print(best_fw_qr_models[5]['coeffs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.45234509, 0.58245277, 0.26675877, 0.24100319, 0.19918756,\n",
       "       0.12594814])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_fw_qr_models[5]['coeffs']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.45234509, 0.62345   , 0.25488273, 0.20339287, 0.2800554 ])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models[4]['coeffs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class singleFWModel(best_submodel_abstract):\n",
    "    def __init__(self, order : int, currFeatures=tuple(), feature=\"\"):\n",
    "        super(singleFWModel, self).__init__();\n",
    "        self.currentFeatures = currFeatures;\n",
    "        self.last_addedFeatures = feature;\n",
    "        self.order = order;\n",
    "    def getAllFeatures(self):\n",
    "        return self.currentFeatures + (self.last_addedFeatures,);\n",
    "   \n",
    "    def _update_best_model(self, pipeline, subset, mse, col_names,):\n",
    "        super(singleFWModel, self)._update_best_model(pipeline, subset, mse, col_names);\n",
    "        self.last_addedFeatures = col_names[-1];\n",
    "\n",
    "    def fit(self, X, y, isItwithoutBias=True):\n",
    "        X_no_bias   = self._removeBias(X, len(self.currentFeatures), isItwithoutBias);\n",
    "        if self.column_names and self.currentFeatures:\n",
    "            self.currFeatureIdx  = tuple([ii for (ii,el) in enumerate(self.column_names) if el in self.currentFeatures]);\n",
    "        else:\n",
    "            self.currFeatureIdx = self.currentFeatures;\n",
    "        errors = error_sequence();\n",
    "        if not self.currentFeatures:\n",
    "            temp_pipe, mse_sk = self.fit1Step(np.ones((X_no_bias.shape[0],1)), y, (0,));\n",
    "            errors.addNewElement((\"intercept\",), mse_sk, (0,));\n",
    "            self._update_best_model(temp_pipe, None, mse_sk, tuple(('intercept',)));\n",
    "            return;\n",
    "        err = np.infty;\n",
    "        used_features_idx = list(self.currFeatureIdx);\n",
    "        used_features_idx.append(-1);#append a fake element that is deleted in the for\n",
    "        errors = error_sequence();\n",
    "        unused_features = tuple([el for el in self.column_names if el not in self.currentFeatures]);\n",
    "        for ff in unused_features:\n",
    "            used_features_idx = used_features_idx[:-1]; #discard the last added\n",
    "            used_features_idx.append(self.column_names.index(ff));\n",
    "            # copy to have the same type instead of declaring\n",
    "            temp_pipe, mse_sk = self.fit1Step(X_no_bias, y, tuple(used_features_idx));\n",
    "            errors.addNewElement(self.column_names, mse_sk, used_features_idx);\n",
    "            if mse_sk < err:\n",
    "                err = mse_sk;\n",
    "                self._update_best_model(temp_pipe, used_features_idx,\n",
    "                                        mse_sk, list(self.currentFeatures) + [ff,]);\n",
    "        self.all_errors = errors;\n",
    "\n",
    "class FWComponentMethod:\n",
    "    def updateTarget(self, y, model=None, X=None):\n",
    "        return y;\n",
    "\n",
    "class OrthogonalFWComponentMethod(FWComponentMethod):\n",
    "    def updateTarget(self, y, model=None, X=None):\n",
    "        return (y-model.predit(X));\n",
    "        \n",
    "#Decorator pattern\n",
    "class best_fw_sk(AllBestModels, FWComponentMethod):\n",
    "    def __init__(self, stepMethod : FWComponentMethod):\n",
    "        super(best_fw_sk, self).__init__();\n",
    "        self._componentStepMethod = stepMethod;\n",
    "    \n",
    "    def fit(self, X, y, num_features, isItwithoutBias=True):\n",
    "        used_features = list();\n",
    "        y_new = y;\n",
    "        for num_features in np.arange(0,X.shape[1]+1):\n",
    "            temp = singleFWModel(num_features, currFeatures=tuple(used_features));\n",
    "            temp.fit(X, y_new);\n",
    "            y_new = self.updateTarget(y_new, temp, X);\n",
    "            self.bestModels[num_features] = temp;\n",
    "            used_features =  used_features + [temp.last_addedFeatures,];\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: `singleFWModel` has some useless attributes coming from best_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.45234509 0.62345    0.25488273 0.2800554  0.20339287]\n",
      "[2.45234509 0.62345    0.25488273 0.2800554  0.20339287]\n"
     ]
    }
   ],
   "source": [
    "stdFit = FWComponentMethod();\n",
    "orthFit = OrthogonalFWComponentMethod();\n",
    "l = best_fw_sk(stdFit);\n",
    "l.fit(X_train, y_train, 5);\n",
    "print(l.bestModels[4].model.get_intercept_coef());\n",
    "#array([2.45234509, 0.64128976, 0.34852683, 0.22422118])\n",
    "#array([2.45234509, 0.62345   , 0.25488273, 0.20339287, 0.2800554 ]) \n",
    "#array([2.45234509, 0.58245277, 0.26675877, 0.19918756, 0.24100319, 0.12594814]) #best model[5]\n",
    "\n",
    "orthFit = OrthogonalFWComponentMethod();\n",
    "l2 = best_fw_sk(stdFit);\n",
    "l2.fit(X_train, y_train, 5);\n",
    "print(l2.bestModels[4].model.get_intercept_coef());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orthogonal dependent fw stepwise class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class\n",
    "#here is the difference from normal forward stepwise\n",
    "    y_new = y_new - y_pred;\n",
    "  #  l_feat.remove(best_fw_orth_dep_subset['names'][-1]);\n",
    "   # best_fw_orth_dep_models[\"error_sequence\"].append(best_fw_orth_dep_subset['err']);\n",
    "    #best_fw_orth_dep_models[num_features] = best_fw_orth_dep_subset.copy();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backword stepwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97, 9) (9,)\n",
      "127.91765888525164\n"
     ]
    }
   ],
   "source": [
    "#sklearn does not support\n",
    "import itertools;\n",
    "from scipy.linalg import inv\n",
    "num_features = X_b.shape[1]-1;\n",
    "#intercept only\n",
    "X_small = X_b.copy();#np.copy(X_b[:,0]).reshape(-1,1); #np.ones\n",
    "b_man  = scipy.linalg.inv(X_small.T.dot(X_small)).dot(X_small.T.dot(y_train));\n",
    "lr = LinearRegression();\n",
    "lr.fit(X_small, y_train);\n",
    "y_pred_sk  = lr.predict(X_small);\n",
    "print(X_small.shape, b_man.shape)\n",
    "y_pred_man = X_small.dot(b_man.reshape(-1,1));\n",
    "rss_sk  = np.sum(np.square(y_train-y_pred_sk));\n",
    "rss_man = np.sum(np.square(y_train-y_pred_man.reshape(y_train.shape)));\n",
    "best_bw_models = {num_features : dict()};\n",
    "best_bw_subset = dict();\n",
    "best_bw_subset['names']      = list(X_train.columns);\n",
    "best_bw_subset['indexes']    = [ii for ii in np.arange(0,num_features+1)]; #wrt X_with_bias_coeffs\n",
    "best_bw_subset['coeffs']     = b_man;\n",
    "best_bw_subset['err']        = rss_man;\n",
    "best_bw_subset['all_errors'] = [];\n",
    "best_bw_subset['skl_model']  = lr;\n",
    "best_bw_models[num_features] = best_bw_subset.copy();\n",
    "best_bw_models[\"error_sequence\"] = list();\n",
    "best_bw_models[\"z_scores\"] = list();\n",
    "best_bw_models[\"error_sequence\"].append(best_fw_subset['err']);\n",
    "#best_bw_subset['indexes'] = [np.arange(0,num_features+1)];\n",
    "orig_num_features = num_features;\n",
    "indexes = [ii for ii in range(0,10)];\n",
    "for num_features in np.arange(1,len(X_train.columns)+1):\n",
    "    XX = scipy.linalg.inv(X_small.T.dot(X_small));\n",
    "    z_score_worst = np.infty;\n",
    "    errors = {\"features\":list(), \"errors\":list()};\n",
    "    normalized_rss = rss_man/(len(X_train-orig_num_features+num_features -1))\n",
    "    \n",
    "    for k,ff in enumerate(best_bw_subset['names']):\n",
    "        z_score = b_man[k]/(np.sqrt(normalized_rss*XX[k,k]));\n",
    "        best_bw_models[\"z_scores\"].append(z_scores);\n",
    "        if abs(z_score) < z_score_worst:\n",
    "            z_score_worst = z_score;\n",
    "            k_worst = k;\n",
    "            ff_worst = ff;\n",
    "            best_bw_subset['err'] = rss_man;\n",
    "\n",
    "    best_bw_subset['names'].remove(ff_worst);\n",
    "    best_bw_subset['indexes'].remove(X_train.columns.get_loc(ff_worst)+1);#wrt X_with_bias_coeffs\n",
    "    y_pred_man = X_small.dot(b_man);   \n",
    "    rss_man = np.sum(np.square(y_train-y_pred_man));\n",
    "    X_small = X_b[:, best_bw_subset['indexes']];\n",
    "    b_man  = scipy.linalg.inv(X_small.T.dot(X_small)).dot(X_small.T.dot(y_train));\n",
    "    best_bw_subset['coeffs'] = b_man.copy();\n",
    "    best_bw_subset['err']    = rss_man;\n",
    "    best_bw_models[orig_num_features-num_features] = best_bw_subset.copy();\n",
    "    best_bw_models[\"error_sequence\"].insert(0, best_bw_subset[\"err\"]);\n",
    "    \n",
    "\n",
    "\n",
    "#Now it contains only 0\n",
    "\n",
    "X_small = X_b[:, best_bw_subset['indexes']];\n",
    "b_man  = scipy.linalg.inv(X_small.T.dot(X_small)).dot(X_small.T.dot(y_train));\n",
    "y_pred_man = X_small.dot(b_man);   \n",
    "rss_man = np.sum(np.square(y_train-y_pred_man));\n",
    "print(rss_man)\n",
    "best_bw_subset['err']    = rss_man;\n",
    "best_bw_models[\"error_sequence\"].insert(0, best_bw_subset[\"err\"]);\n",
    "XX = scipy.linalg.inv(X_small.T.dot(X_small));\n",
    "errors = {\"features\":list(), \"errors\":list()};\n",
    "normalized_rss = rss_man/(len(X_train-orig_num_features+num_features -1))\n",
    "z_score = b_man[k]/(np.sqrt(normalized_rss*XX[k,k]));\n",
    "best_bw_subset['names'] = ['intercept',]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.47838688,  0.70243067,  0.32512188, -0.12620984,  0.18030652])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_bw_models[4][\"coeffs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.47838688, 0.61967302, 0.22845699, 0.29055615, 0.11344257])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_fw_models[4][\"coeffs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stagewise regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97, 9)\n",
      "0.8434274382607599\n",
      "0.8434274382607599\n",
      "[0.26100874]\n",
      "[0.26100874]\n",
      "[0.15519087]\n",
      "[0.15519087]\n",
      "[-0.15684236]\n",
      "[-0.15684236]\n",
      "[0.08818995]\n",
      "[0.08818995]\n",
      "[-0.09316011]\n",
      "[-0.09316011]\n",
      "[0.11129984]\n",
      "[0.11129984]\n",
      "[0.06466917]\n",
      "[0.06466917]\n",
      "[-0.06737883]\n",
      "[-0.06737883]\n",
      "[0.04535345]\n",
      "[0.04535345]\n",
      "[-0.04331858]\n",
      "[-0.04331858]\n",
      "[-0.02499753]\n",
      "[-0.02499753]\n",
      "[0.03693757]\n",
      "[0.03693757]\n",
      "[-0.02350057]\n",
      "[-0.02350057]\n",
      "[0.02171228]\n",
      "[0.02171228]\n",
      "[0.01954552]\n",
      "[0.01954552]\n",
      "[-0.02046127]\n",
      "[-0.02046127]\n",
      "[0.02127011]\n",
      "[0.02127011]\n",
      "[-0.01473005]\n",
      "[-0.01473005]\n",
      "[-0.00906994]\n",
      "[-0.00906994]\n",
      "[0.01479569]\n",
      "[0.01479569]\n",
      "[-0.00995915]\n",
      "[-0.00995915]\n",
      "[0.00901681]\n",
      "[0.00901681]\n",
      "[0.00547287]\n",
      "[0.00547287]\n",
      "[-0.00460382]\n",
      "[-0.00460382]\n",
      "[0.00738321]\n",
      "[0.00738321]\n",
      "[-0.00496972]\n",
      "[-0.00496972]\n",
      "[0.00334517]\n",
      "[0.00334517]\n",
      "[-0.00369254]\n",
      "[-0.00369254]\n",
      "[0.0031471]\n",
      "[0.0031471]\n",
      "[-0.00229807]\n",
      "[-0.00229807]\n",
      "[0.00306234]\n",
      "[0.00306234]\n",
      "[-0.00162514]\n",
      "[-0.00162514]\n",
      "[-0.0013691]\n",
      "[-0.0013691]\n",
      "[0.00162386]\n",
      "[0.00162386]\n",
      "[0.0011997]\n",
      "[0.0011997]\n",
      "[-0.00111989]\n",
      "[-0.00111989]\n",
      "[0.00101244]\n",
      "[0.00101244]\n",
      "[-0.0008496]\n"
     ]
    }
   ],
   "source": [
    "#sklearn does not support\n",
    "import itertools;\n",
    "from scipy.linalg import inv\n",
    "\n",
    "\n",
    "print(X_b.shape)\n",
    "#intercept only\n",
    "X_small = np.copy(X_b[:,0]).reshape(-1,1); #np.ones\n",
    "b_man  = scipy.linalg.inv(X_small.T.dot(X_small)).dot(X_small.T.dot(y_train));\n",
    "\n",
    "y_pred_man = X_small.dot(b_man);\n",
    "rss_man = np.sum(np.square(y_train-y_pred_man.reshape(y_train.shape)));\n",
    "best_sw_models = dict();\n",
    "\n",
    "residual = y_train - y_pred_man;\n",
    "best_sw_models['coeffs'] = np.concatenate((b_man.reshape(1,1), np.zeros((X_train.shape[1],1))), axis=0);\n",
    "#best_sw_models['error_sequence'] = list();\n",
    "#best_sw_models['error_sequence'].append(residual);\n",
    "#best_sw_models['coeffs_history'] = list();\n",
    "#best_sw_models['coeffs_history'].append(b_man);\n",
    "\n",
    "#best_sw_models['coeffs_updated'] = list();\n",
    "#best_sw_models['coeffs_updated'].append(0);\n",
    "count = 0;\n",
    "\n",
    "l_feat = list(X_train.columns);\n",
    "while 1:\n",
    "    #print(residual)\n",
    "    max_corr = 0;\n",
    "    for ff in l_feat:\n",
    "        idx = X_train.columns.get_loc(ff)+1;\n",
    "        x_k = X_b[:,idx];\n",
    "        corr = x_k.dot(residual)/len(x_k);\n",
    "        if abs(corr) > abs(max_corr):\n",
    "           max_idx = idx;\n",
    "           max_corr = corr;\n",
    "    print(max_corr)\n",
    "    if abs(max_corr)<0.001 or count>10000:\n",
    "        break;\n",
    "    print(max_corr)\n",
    "    x_most_corr = X_b[:, max_idx];\n",
    "    b_most_corr = (x_most_corr.T.dot(x_most_corr))**(-1)*(x_most_corr.T.dot(residual));\n",
    "    best_sw_models['coeffs'][max_idx] = best_sw_models['coeffs'][max_idx] + b_most_corr;\n",
    "    y_hat = X_b.dot(best_sw_models['coeffs']);\n",
    "    residual = y_train.values.reshape(-1,1) - y_hat;\n",
    "    #best_sw_models['error_sequence'].append(residual);\n",
    "    count += 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.47838688],\n",
       "       [ 0.66196462],\n",
       "       [ 0.26415584],\n",
       "       [-0.15652642],\n",
       "       [ 0.13968469],\n",
       "       [ 0.31190695],\n",
       "       [-0.14510743],\n",
       "       [ 0.0343617 ],\n",
       "       [ 0.12512751]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_sw_models['coeffs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.47838688,  0.6617092 ,  0.26510309, -0.15737767,  0.13958604,\n",
       "        0.31369926, -0.14751935,  0.03536545,  0.1250701 ])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models[8]['coeffs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
