{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!wget https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy as np;\n",
    "import matplotlib.pyplot as plt;\n",
    "from numpy.linalg import inv;\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "x = np.linspace(0,1,100);\n",
    "y = x+1;\n",
    "scaler = StandardScaler();\n",
    "x_scaled = scaler.fit_transform(x.reshape(-1,1));\n",
    "\n",
    "X_b = np.c_[np.ones((len(x_scaled), 1)), x_scaled]\n",
    "theta_ols = inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
    "theta_ols\n",
    "plt.plot(x_scaled, y)\n",
    "#print(x_scaled[0], x_scaled[-1])\n",
    "theta_ols\n",
    "\n",
    "lr = LinearRegression();\n",
    "lr.fit(X_b, y);\n",
    "print(lr.coef_, lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np;\n",
    "import pandas as pd;\n",
    "import scipy;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"prostate.data\",header=0, delimiter=\"\\t\",);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.579818</td>\n",
       "      <td>2.769459</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.430783</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.994252</td>\n",
       "      <td>3.319626</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>2.691243</td>\n",
       "      <td>74</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.203973</td>\n",
       "      <td>3.282789</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.751416</td>\n",
       "      <td>3.432373</td>\n",
       "      <td>62</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.371564</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    lcavol   lweight  age      lbph  svi       lcp  gleason  \\\n",
       "0           1 -0.579818  2.769459   50 -1.386294    0 -1.386294        6   \n",
       "1           2 -0.994252  3.319626   58 -1.386294    0 -1.386294        6   \n",
       "2           3 -0.510826  2.691243   74 -1.386294    0 -1.386294        7   \n",
       "3           4 -1.203973  3.282789   58 -1.386294    0 -1.386294        6   \n",
       "4           5  0.751416  3.432373   62 -1.386294    0 -1.386294        6   \n",
       "\n",
       "   pgg45      lpsa train  \n",
       "0      0 -0.430783     T  \n",
       "1      0 -0.162519     T  \n",
       "2     20 -0.162519     T  \n",
       "3      0 -0.162519     T  \n",
       "4      0  0.371564     T  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.579818</td>\n",
       "      <td>2.769459</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.430783</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.994252</td>\n",
       "      <td>3.319626</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.510826</td>\n",
       "      <td>2.691243</td>\n",
       "      <td>74</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.203973</td>\n",
       "      <td>3.282789</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.751416</td>\n",
       "      <td>3.432373</td>\n",
       "      <td>62</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.371564</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lcavol   lweight  age      lbph  svi       lcp  gleason  pgg45      lpsa  \\\n",
       "0 -0.579818  2.769459   50 -1.386294    0 -1.386294        6      0 -0.430783   \n",
       "1 -0.994252  3.319626   58 -1.386294    0 -1.386294        6      0 -0.162519   \n",
       "2 -0.510826  2.691243   74 -1.386294    0 -1.386294        7     20 -0.162519   \n",
       "3 -1.203973  3.282789   58 -1.386294    0 -1.386294        6      0 -0.162519   \n",
       "4  0.751416  3.432373   62 -1.386294    0 -1.386294        6      0  0.371564   \n",
       "\n",
       "  train  \n",
       "0     T  \n",
       "1     T  \n",
       "2     T  \n",
       "3     T  \n",
       "4     T  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop first column\n",
    "df.drop([df.columns[0]],inplace=True, axis='columns');\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 97 entries, 0 to 96\n",
      "Data columns (total 10 columns):\n",
      "lcavol     97 non-null float64\n",
      "lweight    97 non-null float64\n",
      "age        97 non-null int64\n",
      "lbph       97 non-null float64\n",
      "svi        97 non-null int64\n",
      "lcp        97 non-null float64\n",
      "gleason    97 non-null int64\n",
      "pgg45      97 non-null int64\n",
      "lpsa       97 non-null float64\n",
      "train      97 non-null object\n",
      "dtypes: float64(5), int64(4), object(1)\n",
      "memory usage: 7.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.350010</td>\n",
       "      <td>3.628943</td>\n",
       "      <td>63.865979</td>\n",
       "      <td>0.100356</td>\n",
       "      <td>0.216495</td>\n",
       "      <td>-0.179366</td>\n",
       "      <td>6.752577</td>\n",
       "      <td>24.381443</td>\n",
       "      <td>2.478387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.178625</td>\n",
       "      <td>0.428411</td>\n",
       "      <td>7.445117</td>\n",
       "      <td>1.450807</td>\n",
       "      <td>0.413995</td>\n",
       "      <td>1.398250</td>\n",
       "      <td>0.722134</td>\n",
       "      <td>28.204035</td>\n",
       "      <td>1.154329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.347074</td>\n",
       "      <td>2.374906</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.430783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.512824</td>\n",
       "      <td>3.375880</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.731656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.446919</td>\n",
       "      <td>3.623007</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.300105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.798508</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.591516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.127041</td>\n",
       "      <td>3.876396</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>1.558145</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.178655</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>3.056357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.821004</td>\n",
       "      <td>4.780383</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>2.326302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.904165</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>5.582932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lcavol    lweight        age       lbph        svi        lcp  \\\n",
       "count  97.000000  97.000000  97.000000  97.000000  97.000000  97.000000   \n",
       "mean    1.350010   3.628943  63.865979   0.100356   0.216495  -0.179366   \n",
       "std     1.178625   0.428411   7.445117   1.450807   0.413995   1.398250   \n",
       "min    -1.347074   2.374906  41.000000  -1.386294   0.000000  -1.386294   \n",
       "25%     0.512824   3.375880  60.000000  -1.386294   0.000000  -1.386294   \n",
       "50%     1.446919   3.623007  65.000000   0.300105   0.000000  -0.798508   \n",
       "75%     2.127041   3.876396  68.000000   1.558145   0.000000   1.178655   \n",
       "max     3.821004   4.780383  79.000000   2.326302   1.000000   2.904165   \n",
       "\n",
       "         gleason       pgg45       lpsa  \n",
       "count  97.000000   97.000000  97.000000  \n",
       "mean    6.752577   24.381443   2.478387  \n",
       "std     0.722134   28.204035   1.154329  \n",
       "min     6.000000    0.000000  -0.430783  \n",
       "25%     6.000000    0.000000   1.731656  \n",
       "50%     7.000000   15.000000   2.591516  \n",
       "75%     7.000000   40.000000   3.056357  \n",
       "max     9.000000  100.000000   5.582932  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrrr}\n",
      "\\toprule\n",
      "{} &  lcavol &  lweight &    age &   lbph &    svi &    lcp &  gleason &  pgg45 &   lpsa \\\\\n",
      "\\midrule\n",
      "lcavol  &   1.000 &    0.281 &  0.225 &  0.027 &  0.539 &  0.675 &    0.432 &  0.434 &  0.734 \\\\\n",
      "lweight &   0.281 &    1.000 &  0.348 &  0.442 &  0.155 &  0.165 &    0.057 &  0.107 &  0.433 \\\\\n",
      "age     &   0.225 &    0.348 &  1.000 &  0.350 &  0.118 &  0.128 &    0.269 &  0.276 &  0.170 \\\\\n",
      "lbph    &   0.027 &    0.442 &  0.350 &  1.000 & -0.086 & -0.007 &    0.078 &  0.078 &  0.180 \\\\\n",
      "svi     &   0.539 &    0.155 &  0.118 & -0.086 &  1.000 &  0.673 &    0.320 &  0.458 &  0.566 \\\\\n",
      "lcp     &   0.675 &    0.165 &  0.128 & -0.007 &  0.673 &  1.000 &    0.515 &  0.632 &  0.549 \\\\\n",
      "gleason &   0.432 &    0.057 &  0.269 &  0.078 &  0.320 &  0.515 &    1.000 &  0.752 &  0.369 \\\\\n",
      "pgg45   &   0.434 &    0.107 &  0.276 &  0.078 &  0.458 &  0.632 &    0.752 &  1.000 &  0.422 \\\\\n",
      "lpsa    &   0.734 &    0.433 &  0.170 &  0.180 &  0.566 &  0.549 &    0.369 &  0.422 &  1.000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.corr().round(3).to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data are highly correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lcavol</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.280521</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.027350</td>\n",
       "      <td>0.538845</td>\n",
       "      <td>0.675310</td>\n",
       "      <td>0.432417</td>\n",
       "      <td>0.433652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lweight</th>\n",
       "      <td>0.280521</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.347969</td>\n",
       "      <td>0.442264</td>\n",
       "      <td>0.155385</td>\n",
       "      <td>0.164537</td>\n",
       "      <td>0.056882</td>\n",
       "      <td>0.107354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.347969</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.350186</td>\n",
       "      <td>0.117658</td>\n",
       "      <td>0.127668</td>\n",
       "      <td>0.268892</td>\n",
       "      <td>0.276112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lbph</th>\n",
       "      <td>0.027350</td>\n",
       "      <td>0.442264</td>\n",
       "      <td>0.350186</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.085843</td>\n",
       "      <td>-0.006999</td>\n",
       "      <td>0.077820</td>\n",
       "      <td>0.078460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svi</th>\n",
       "      <td>0.538845</td>\n",
       "      <td>0.155385</td>\n",
       "      <td>0.117658</td>\n",
       "      <td>-0.085843</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.673111</td>\n",
       "      <td>0.320412</td>\n",
       "      <td>0.457648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lcp</th>\n",
       "      <td>0.675310</td>\n",
       "      <td>0.164537</td>\n",
       "      <td>0.127668</td>\n",
       "      <td>-0.006999</td>\n",
       "      <td>0.673111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.514830</td>\n",
       "      <td>0.631528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gleason</th>\n",
       "      <td>0.432417</td>\n",
       "      <td>0.056882</td>\n",
       "      <td>0.268892</td>\n",
       "      <td>0.077820</td>\n",
       "      <td>0.320412</td>\n",
       "      <td>0.514830</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.751905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgg45</th>\n",
       "      <td>0.433652</td>\n",
       "      <td>0.107354</td>\n",
       "      <td>0.276112</td>\n",
       "      <td>0.078460</td>\n",
       "      <td>0.457648</td>\n",
       "      <td>0.631528</td>\n",
       "      <td>0.751905</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           lcavol   lweight       age      lbph       svi       lcp   gleason  \\\n",
       "lcavol   1.000000  0.280521  0.225000  0.027350  0.538845  0.675310  0.432417   \n",
       "lweight  0.280521  1.000000  0.347969  0.442264  0.155385  0.164537  0.056882   \n",
       "age      0.225000  0.347969  1.000000  0.350186  0.117658  0.127668  0.268892   \n",
       "lbph     0.027350  0.442264  0.350186  1.000000 -0.085843 -0.006999  0.077820   \n",
       "svi      0.538845  0.155385  0.117658 -0.085843  1.000000  0.673111  0.320412   \n",
       "lcp      0.675310  0.164537  0.127668 -0.006999  0.673111  1.000000  0.514830   \n",
       "gleason  0.432417  0.056882  0.268892  0.077820  0.320412  0.514830  1.000000   \n",
       "pgg45    0.433652  0.107354  0.276112  0.078460  0.457648  0.631528  0.751905   \n",
       "\n",
       "            pgg45  \n",
       "lcavol   0.433652  \n",
       "lweight  0.107354  \n",
       "age      0.276112  \n",
       "lbph     0.078460  \n",
       "svi      0.457648  \n",
       "lcp      0.631528  \n",
       "gleason  0.751905  \n",
       "pgg45    1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['lpsa'];\n",
    "X = df.drop(['lpsa'],axis=1);\n",
    "X.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled data correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lcavol</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.300232</td>\n",
       "      <td>0.286324</td>\n",
       "      <td>0.063168</td>\n",
       "      <td>0.592949</td>\n",
       "      <td>0.692043</td>\n",
       "      <td>0.426414</td>\n",
       "      <td>0.483161</td>\n",
       "      <td>0.727280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lweight</th>\n",
       "      <td>0.300232</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.316723</td>\n",
       "      <td>0.437042</td>\n",
       "      <td>0.181054</td>\n",
       "      <td>0.156829</td>\n",
       "      <td>0.023558</td>\n",
       "      <td>0.074166</td>\n",
       "      <td>0.598021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.286324</td>\n",
       "      <td>0.316723</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.287346</td>\n",
       "      <td>0.128902</td>\n",
       "      <td>0.172951</td>\n",
       "      <td>0.365915</td>\n",
       "      <td>0.275806</td>\n",
       "      <td>0.345414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lbph</th>\n",
       "      <td>0.063168</td>\n",
       "      <td>0.437042</td>\n",
       "      <td>0.287346</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.139147</td>\n",
       "      <td>-0.088535</td>\n",
       "      <td>0.032992</td>\n",
       "      <td>-0.030404</td>\n",
       "      <td>0.396349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svi</th>\n",
       "      <td>0.592949</td>\n",
       "      <td>0.181054</td>\n",
       "      <td>0.128902</td>\n",
       "      <td>-0.139147</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.671240</td>\n",
       "      <td>0.306875</td>\n",
       "      <td>0.481358</td>\n",
       "      <td>0.451672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lcp</th>\n",
       "      <td>0.692043</td>\n",
       "      <td>0.156829</td>\n",
       "      <td>0.172951</td>\n",
       "      <td>-0.088535</td>\n",
       "      <td>0.671240</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.476437</td>\n",
       "      <td>0.662533</td>\n",
       "      <td>0.434572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gleason</th>\n",
       "      <td>0.426414</td>\n",
       "      <td>0.023558</td>\n",
       "      <td>0.365915</td>\n",
       "      <td>0.032992</td>\n",
       "      <td>0.306875</td>\n",
       "      <td>0.476437</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.757056</td>\n",
       "      <td>0.331608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgg45</th>\n",
       "      <td>0.483161</td>\n",
       "      <td>0.074166</td>\n",
       "      <td>0.275806</td>\n",
       "      <td>-0.030404</td>\n",
       "      <td>0.481358</td>\n",
       "      <td>0.662533</td>\n",
       "      <td>0.757056</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.368055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lpsa</th>\n",
       "      <td>0.727280</td>\n",
       "      <td>0.598021</td>\n",
       "      <td>0.345414</td>\n",
       "      <td>0.396349</td>\n",
       "      <td>0.451672</td>\n",
       "      <td>0.434572</td>\n",
       "      <td>0.331608</td>\n",
       "      <td>0.368055</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           lcavol   lweight       age      lbph       svi       lcp   gleason  \\\n",
       "lcavol   1.000000  0.300232  0.286324  0.063168  0.592949  0.692043  0.426414   \n",
       "lweight  0.300232  1.000000  0.316723  0.437042  0.181054  0.156829  0.023558   \n",
       "age      0.286324  0.316723  1.000000  0.287346  0.128902  0.172951  0.365915   \n",
       "lbph     0.063168  0.437042  0.287346  1.000000 -0.139147 -0.088535  0.032992   \n",
       "svi      0.592949  0.181054  0.128902 -0.139147  1.000000  0.671240  0.306875   \n",
       "lcp      0.692043  0.156829  0.172951 -0.088535  0.671240  1.000000  0.476437   \n",
       "gleason  0.426414  0.023558  0.365915  0.032992  0.306875  0.476437  1.000000   \n",
       "pgg45    0.483161  0.074166  0.275806 -0.030404  0.481358  0.662533  0.757056   \n",
       "lpsa     0.727280  0.598021  0.345414  0.396349  0.451672  0.434572  0.331608   \n",
       "\n",
       "            pgg45      lpsa  \n",
       "lcavol   0.483161  0.727280  \n",
       "lweight  0.074166  0.598021  \n",
       "age      0.275806  0.345414  \n",
       "lbph    -0.030404  0.396349  \n",
       "svi      0.481358  0.451672  \n",
       "lcp      0.662533  0.434572  \n",
       "gleason  0.757056  0.331608  \n",
       "pgg45    1.000000  0.368055  \n",
       "lpsa     0.368055  1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.pipeline import Pipeline\n",
    "std_scaler = StandardScaler();\n",
    "X_train = X[X['train']==\"T\"];\n",
    "y_train = y[X['train']==\"T\"];\n",
    "X_test = X[X['train']==\"F\"];\n",
    "y_test = y[X['train']==\"F\"];\n",
    "X_train = X_train.drop('train',axis=1)\n",
    "#X_scaled = pp.scale(X_train.astype('float')); # this works as the below one\n",
    "X_scaled = std_scaler.fit_transform(X_train.astype('float'));\n",
    "df_scaled = pd.concat([pd.DataFrame(X_scaled), y_train], axis=1, );\n",
    "#-1 because df has still 'train' col\n",
    "df_scaled.columns = df.columns[:-1];\n",
    "df_scaled.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrrr}\n",
      "\\toprule\n",
      "{} &  lcavol &  lweight &    age &   lbph &    svi &    lcp &  gleason &  pgg45 &   lpsa \\\\\n",
      "\\midrule\n",
      "lcavol  &   1.000 &    0.300 &  0.286 &  0.063 &  0.593 &  0.692 &    0.426 &  0.483 &  0.727 \\\\\n",
      "lweight &   0.300 &    1.000 &  0.317 &  0.437 &  0.181 &  0.157 &    0.024 &  0.074 &  0.598 \\\\\n",
      "age     &   0.286 &    0.317 &  1.000 &  0.287 &  0.129 &  0.173 &    0.366 &  0.276 &  0.345 \\\\\n",
      "lbph    &   0.063 &    0.437 &  0.287 &  1.000 & -0.139 & -0.089 &    0.033 & -0.030 &  0.396 \\\\\n",
      "svi     &   0.593 &    0.181 &  0.129 & -0.139 &  1.000 &  0.671 &    0.307 &  0.481 &  0.452 \\\\\n",
      "lcp     &   0.692 &    0.157 &  0.173 & -0.089 &  0.671 &  1.000 &    0.476 &  0.663 &  0.435 \\\\\n",
      "gleason &   0.426 &    0.024 &  0.366 &  0.033 &  0.307 &  0.476 &    1.000 &  0.757 &  0.332 \\\\\n",
      "pgg45   &   0.483 &    0.074 &  0.276 & -0.030 &  0.481 &  0.663 &    0.757 &  1.000 &  0.368 \\\\\n",
      "lpsa    &   0.727 &    0.598 &  0.345 &  0.396 &  0.452 &  0.435 &    0.332 &  0.368 &  1.000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_scaled.corr().round(3).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.pipeline import Pipeline\n",
    "std_scaler = StandardScaler();\n",
    "X_train = X[X['train']==\"T\"];\n",
    "y_train = y[X['train']==\"T\"];\n",
    "X_test = X[X['train']==\"F\"];\n",
    "y_test = y[X['train']==\"F\"];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.30832816e-17 -4.97114787e-18 -8.34324318e-16  6.62819716e-18\n",
      "  3.97691830e-17 -4.30832816e-17  4.92143639e-16 -3.31409858e-17]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fra/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "#X_train = X;\n",
    "#y_train = y;\n",
    "X_train.drop(['train'], axis=1, inplace=True)\n",
    "#del X, y\n",
    "#### We assume data have been already shuffled.\n",
    "#X_train.head()\n",
    "X_scaled = pp.scale(X_train.astype('float'));\n",
    "print(X_scaled.mean(axis=0))\n",
    "print(X_scaled.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          lcavol    lweight        age       lbph        svi        lcp  \\\n",
      "count  67.000000  67.000000  67.000000  67.000000  67.000000  67.000000   \n",
      "mean    1.313492   3.626108  64.746269   0.071440   0.223881  -0.214203   \n",
      "std     1.242590   0.476601   7.502208   1.463655   0.419989   1.400735   \n",
      "min    -1.347074   2.374906  41.000000  -1.386294   0.000000  -1.386294   \n",
      "25%     0.488279   3.330360  61.000000  -1.386294   0.000000  -1.386294   \n",
      "50%     1.467874   3.598681  65.000000  -0.051293   0.000000  -0.798508   \n",
      "75%     2.349065   3.883610  69.000000   1.547506   0.000000   0.994793   \n",
      "max     3.821004   4.780383  79.000000   2.326302   1.000000   2.656757   \n",
      "\n",
      "         gleason       pgg45  \n",
      "count  67.000000   67.000000  \n",
      "mean    6.731343   26.268657  \n",
      "std     0.708864   29.301764  \n",
      "min     6.000000    0.000000  \n",
      "25%     6.000000    0.000000  \n",
      "50%     7.000000   15.000000  \n",
      "75%     7.000000   50.000000  \n",
      "max     9.000000  100.000000  \n",
      "                  0             1             2             3             4  \\\n",
      "count  6.700000e+01  6.700000e+01  6.700000e+01  6.700000e+01  6.700000e+01   \n",
      "mean   9.610886e-17 -7.125312e-17 -8.078115e-16  2.651279e-17 -2.121023e-16   \n",
      "std    1.007547e+00  1.007547e+00  1.007547e+00  1.007547e+00  1.007547e+00   \n",
      "min   -2.157304e+00 -2.645075e+00 -3.189126e+00 -1.003472e+00 -5.370862e-01   \n",
      "25%   -6.691190e-01 -6.252199e-01 -5.031242e-01 -1.003472e+00 -5.370862e-01   \n",
      "50%    1.251804e-01 -5.798078e-02  3.407614e-02 -8.448679e-02 -5.370862e-01   \n",
      "75%    8.396889e-01  5.443671e-01  5.712765e-01  1.016091e+00 -5.370862e-01   \n",
      "max    2.033202e+00  2.440170e+00  1.914277e+00  1.552196e+00  1.861899e+00   \n",
      "\n",
      "                  5             6             7  \n",
      "count  6.700000e+01  6.700000e+01  6.700000e+01  \n",
      "mean   1.955318e-16  6.114512e-16  5.965377e-17  \n",
      "std    1.007547e+00  1.007547e+00  1.007547e+00  \n",
      "min   -8.430840e-01 -1.039499e+00 -9.032532e-01  \n",
      "25%   -8.430840e-01 -1.039499e+00 -9.032532e-01  \n",
      "50%   -4.202897e-01  3.818568e-01 -3.874751e-01  \n",
      "75%    8.696292e-01  3.818568e-01  8.160072e-01  \n",
      "max    2.065078e+00  3.224568e+00  2.535268e+00  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 67 entries, 0 to 95\n",
      "Data columns (total 8 columns):\n",
      "lcavol     67 non-null float64\n",
      "lweight    67 non-null float64\n",
      "age        67 non-null int64\n",
      "lbph       67 non-null float64\n",
      "svi        67 non-null int64\n",
      "lcp        67 non-null float64\n",
      "gleason    67 non-null int64\n",
      "pgg45      67 non-null int64\n",
      "dtypes: float64(4), int64(4)\n",
      "memory usage: 4.7 KB\n"
     ]
    }
   ],
   "source": [
    "print(X_train.describe());\n",
    "print(pd.DataFrame(X_scaled).describe());\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.30832816e-17 -4.97114787e-18 -8.34324318e-16  6.62819716e-18\n",
      "  3.97691830e-17 -4.30832816e-17  4.92143639e-16 -3.31409858e-17]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "X_scaled = std_scaler.fit_transform(X_train.astype(float));\n",
    "print(np.mean(X_scaled, axis=0));\n",
    "print(np.std(X_scaled, axis=0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lcavol</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.300232</td>\n",
       "      <td>0.286324</td>\n",
       "      <td>0.063168</td>\n",
       "      <td>0.592949</td>\n",
       "      <td>0.692043</td>\n",
       "      <td>0.426414</td>\n",
       "      <td>0.483161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lweight</th>\n",
       "      <td>0.300232</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.316723</td>\n",
       "      <td>0.437042</td>\n",
       "      <td>0.181054</td>\n",
       "      <td>0.156829</td>\n",
       "      <td>0.023558</td>\n",
       "      <td>0.074166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.286324</td>\n",
       "      <td>0.316723</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.287346</td>\n",
       "      <td>0.128902</td>\n",
       "      <td>0.172951</td>\n",
       "      <td>0.365915</td>\n",
       "      <td>0.275806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lbph</th>\n",
       "      <td>0.063168</td>\n",
       "      <td>0.437042</td>\n",
       "      <td>0.287346</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.139147</td>\n",
       "      <td>-0.088535</td>\n",
       "      <td>0.032992</td>\n",
       "      <td>-0.030404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svi</th>\n",
       "      <td>0.592949</td>\n",
       "      <td>0.181054</td>\n",
       "      <td>0.128902</td>\n",
       "      <td>-0.139147</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.671240</td>\n",
       "      <td>0.306875</td>\n",
       "      <td>0.481358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lcp</th>\n",
       "      <td>0.692043</td>\n",
       "      <td>0.156829</td>\n",
       "      <td>0.172951</td>\n",
       "      <td>-0.088535</td>\n",
       "      <td>0.671240</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.476437</td>\n",
       "      <td>0.662533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gleason</th>\n",
       "      <td>0.426414</td>\n",
       "      <td>0.023558</td>\n",
       "      <td>0.365915</td>\n",
       "      <td>0.032992</td>\n",
       "      <td>0.306875</td>\n",
       "      <td>0.476437</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.757056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgg45</th>\n",
       "      <td>0.483161</td>\n",
       "      <td>0.074166</td>\n",
       "      <td>0.275806</td>\n",
       "      <td>-0.030404</td>\n",
       "      <td>0.481358</td>\n",
       "      <td>0.662533</td>\n",
       "      <td>0.757056</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           lcavol   lweight       age      lbph       svi       lcp   gleason  \\\n",
       "lcavol   1.000000  0.300232  0.286324  0.063168  0.592949  0.692043  0.426414   \n",
       "lweight  0.300232  1.000000  0.316723  0.437042  0.181054  0.156829  0.023558   \n",
       "age      0.286324  0.316723  1.000000  0.287346  0.128902  0.172951  0.365915   \n",
       "lbph     0.063168  0.437042  0.287346  1.000000 -0.139147 -0.088535  0.032992   \n",
       "svi      0.592949  0.181054  0.128902 -0.139147  1.000000  0.671240  0.306875   \n",
       "lcp      0.692043  0.156829  0.172951 -0.088535  0.671240  1.000000  0.476437   \n",
       "gleason  0.426414  0.023558  0.365915  0.032992  0.306875  0.476437  1.000000   \n",
       "pgg45    0.483161  0.074166  0.275806 -0.030404  0.481358  0.662533  0.757056   \n",
       "\n",
       "            pgg45  \n",
       "lcavol   0.483161  \n",
       "lweight  0.074166  \n",
       "age      0.275806  \n",
       "lbph    -0.030404  \n",
       "svi      0.481358  \n",
       "lcp      0.662533  \n",
       "gleason  0.757056  \n",
       "pgg45    1.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_scaled, columns=X_train.columns).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lcavol', 'lweight', 'age', 'lbph', 'svi', 'lcp', 'gleason', 'pgg45'], dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.08701959, 0.13250132, 0.10558798, 0.10135462, 0.1023518 ,\n",
       "        0.12445059, 0.15364444, 0.14151003, 0.1583969 ]),\n",
       " array([28.18152744,  5.36629046,  2.75078939, -1.39590898,  2.05584563,\n",
       "         2.46925518, -1.86691264, -0.14668121,  1.73783972]))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "#X_b = np.c_[np.ones((len(X_scaled), 1)), X_scaled]\n",
    "\n",
    "\n",
    "class customLinearRegression(LinearRegression):\n",
    "    def __init__(self):\n",
    "        super(customLinearRegression, self).__init__();\n",
    "    def z_scores(self, y, X, bias=False):\n",
    "        p = len(self.coef_);\n",
    "        if (bias):\n",
    "            y_pred = self.predict(X[:,1:]);\n",
    "            X_with_bias = X;\n",
    "        else:\n",
    "            y_pred = self.predict(X);\n",
    "            X_with_bias = np.c_[np.ones((X.shape[0], 1)), X];\n",
    "        sigma_hat_sq = np.sum(np.square(y_train-y_pred))/(len(y_train)-p-1);\n",
    "        std_err  = np.sqrt(np.diag(inv(X_with_bias.T.dot(X_with_bias)))*sigma_hat_sq);\n",
    "        z_scores = np.multiply(np.append(self.intercept_, self.coef_), 1/std_err);\n",
    "        return std_err, z_scores;\n",
    "    def get_intercept_coef(self):\n",
    "        return np.append(self.intercept_, self.coef_);\n",
    "lr = customLinearRegression();\n",
    "lr.fit( X_scaled, y_train);\n",
    "lr.z_scores(y_train, X_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.71104059,  0.29045029, -0.14148182,  0.21041951,  0.30730025,\n",
       "        -0.28684075, -0.02075686,  0.27526843]), 2.4523450850746267)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_, lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.00000000e+00  4.30832816e-17 -4.97114787e-18 -8.34324318e-16\n",
      "  6.62819716e-18  3.97691830e-17 -4.30832816e-17  4.92143639e-16\n",
      " -3.31409858e-17]\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import inv;\n",
    "X_b = np.c_[np.ones((len(X_scaled), 1)), X_scaled];\n",
    "print(np.mean(X_b, axis=0));\n",
    "theta = inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.45234509,  0.71104059,  0.29045029, -0.14148182,  0.21041951,\n",
       "        0.30730025, -0.28684075, -0.02075686,  0.27526843])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice that the stochastic gradient coefficients are slightly different "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.45234509,  0.71104059,  0.29045029, -0.14148182,  0.21041951,\n",
       "         0.30730025, -0.28684075, -0.02075686,  0.27526843]),\n",
       " array([ 2.45234509,  0.71104059,  0.29045029, -0.14148182,  0.21041951,\n",
       "         0.30730025, -0.28684075, -0.02075686,  0.27526843]))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_iter = 1000;\n",
    "np.random.seed(42);\n",
    "eta = 0.1\n",
    "theta_gd = np.random.randn(X_b.shape[1],1);\n",
    "for ii in range(n_iter):\n",
    "    gradient =  -2/len(X_b)*X_b.T.dot(np.c_[y_train] - X_b.dot(theta_gd));\n",
    "    theta_gd = theta_gd - eta*gradient;\n",
    "    \n",
    "theta, theta_gd.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_scaled);\n",
    "y_pred_man = X_b.dot(theta);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **residual sum of squares (RSS)** and **Mean square error(MSE)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.43919976805833433, 0.43919976805833433)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error;\n",
    "np.sum(np.square(y_train-y_pred))/len(y_pred), mean_squared_error(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.43919976805833433, 0.43919976805833433)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error;\n",
    "np.sum(np.square(y_train-y_pred_man))/len(y_pred), mean_squared_error(y_train, y_pred_man)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Std. error</th>\n",
       "      <th>$Z$ score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>2.45</td>\n",
       "      <td>0.09</td>\n",
       "      <td>28.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lcavol</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.13</td>\n",
       "      <td>5.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lweight</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lbph</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svi</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lcp</th>\n",
       "      <td>-0.29</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-1.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gleason</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgg45</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Coefficient  Std. error  $Z$ score\n",
       "intercept         2.45        0.09      28.18\n",
       "lcavol            0.71        0.13       5.37\n",
       "lweight           0.29        0.11       2.75\n",
       "age              -0.14        0.10      -1.40\n",
       "lbph              0.21        0.10       2.06\n",
       "svi               0.31        0.12       2.47\n",
       "lcp              -0.29        0.15      -1.87\n",
       "gleason          -0.02        0.14      -0.15\n",
       "pgg45             0.28        0.16       1.74"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apparently, scikit does not support statistical inference delibarately\n",
    "del z_scores, std_err;\n",
    "def Z_score(y_train, theta, X_with_bias):\n",
    "    p = X_with_bias.shape[1]-1;\n",
    "    y_pred = X_with_bias.dot(theta);\n",
    "    sigma_hat_sq = np.sum(np.square(y_train-y_pred))/(len(y_train)-p-1);\n",
    "    std_err  = np.sqrt(np.diag(inv(X_with_bias.T.dot(X_with_bias)))*sigma_hat_sq);\n",
    "    z_scores = np.multiply(theta, 1/std_err);\n",
    "    return z_scores, std_err;\n",
    "\n",
    "z_scores, std_err = Z_score(y_train, theta, X_b);\n",
    "\n",
    "pd.DataFrame({\"Coefficient\": theta, \"Std. error\" : std_err,\n",
    "              r\"$Z$ score\" : z_scores.ravel(),},\n",
    "             index=pd.Index([\"intercept\"]).append(X_train.columns)\n",
    "            ).round(2).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the extended linear Regression class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Std. error</th>\n",
       "      <th>$Z$ score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>2.45</td>\n",
       "      <td>0.09</td>\n",
       "      <td>28.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lcavol</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.13</td>\n",
       "      <td>5.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lweight</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lbph</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svi</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lcp</th>\n",
       "      <td>-0.29</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-1.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gleason</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgg45</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Coefficient  Std. error  $Z$ score\n",
       "intercept         2.45        0.09      28.18\n",
       "lcavol            0.71        0.13       5.37\n",
       "lweight           0.29        0.11       2.75\n",
       "age              -0.14        0.10      -1.40\n",
       "lbph              0.21        0.10       2.06\n",
       "svi               0.31        0.12       2.47\n",
       "lcp              -0.29        0.15      -1.87\n",
       "gleason          -0.02        0.14      -0.15\n",
       "pgg45             0.28        0.16       1.74"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_err_lr, z_scores_lr = lr.z_scores(y_train, X_scaled);\n",
    "pd.DataFrame({\"Coefficient\": lr.get_intercept_coef(), \"Std. error\" : std_err_lr,\n",
    "              r\"$Z$ score\" : z_scores_lr},\n",
    "             index=pd.Index([\"intercept\"]).append(X_train.columns)\n",
    "            ).round(2).head(len(lr.coef_)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "{} &  Coefficient &  Std. error &  \\textbackslash \\$Z\\textbackslash \\$ score \\\\\n",
      "\\midrule\n",
      "intercept &         2.45 &        0.09 &        28.18 \\\\\n",
      "lcavol    &         0.71 &        0.13 &         5.37 \\\\\n",
      "lweight   &         0.29 &        0.11 &         2.75 \\\\\n",
      "age       &        -0.14 &        0.10 &        -1.40 \\\\\n",
      "lbph      &         0.21 &        0.10 &         2.06 \\\\\n",
      "svi       &         0.31 &        0.12 &         2.47 \\\\\n",
      "lcp       &        -0.29 &        0.15 &        -1.87 \\\\\n",
      "gleason   &        -0.02 &        0.14 &        -0.15 \\\\\n",
      "pgg45     &         0.28 &        0.16 &         1.74 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame({\"Coefficient\": lr.get_intercept_coef(), \"Std. error\" : std_err_lr,\n",
    "              \"$Z$ score\" : z_scores_lr},\n",
    "             index=pd.Index([\"intercept\"]).append(X_train.columns)\n",
    "            ).round(2).to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best subset selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn does not support\n",
    "import itertools;\n",
    "from scipy.linalg import inv\n",
    "\n",
    "#intercept only\n",
    "X_small = np.copy(X_b[:,0]).reshape(-1,1); #np.ones\n",
    "b_man  = scipy.linalg.inv(X_small.T.dot(X_small)).dot(X_small.T.dot(y_train));\n",
    "lr = customLinearRegression();\n",
    "lr.fit(X_small, y_train);\n",
    "y_pred_sk  = lr.predict(X_small);\n",
    "y_pred_man = X_small.dot(b_man);\n",
    "rss_sk  = np.sum(np.square(y_train-y_pred_sk));\n",
    "rss_man = np.sum(np.square(y_train-y_pred_man.reshape(y_train.shape)));\n",
    "num_features = X_b.shape[1]-1;\n",
    "best_models = {num_features : dict()};\n",
    "best_subset = dict();\n",
    "best_subset['names']      = [\"intercept\",];\n",
    "best_subset['indexes']    = [0]; #wrt X_with_bias_coeffs\n",
    "best_subset['coeffs']     = b_man;\n",
    "best_subset['err']        = rss_man;\n",
    "errors = {\"features\":\"intercept\", \"errors\":rss_man};\n",
    "best_subset['all_errors'] = errors;\n",
    "best_subset['skl_model']  = lr;\n",
    "best_models[0] = best_subset;\n",
    "best_models[\"error_sequence\"] = list();\n",
    "best_models[\"error_sequence\"].append(best_subset['err']);\n",
    "\n",
    "for num_features in np.arange(1,len(X_train.columns)+1):\n",
    "    err = np.infty;\n",
    "    best_subset = dict();\n",
    "    errors = {\"features\":list(), \"errors\":list()};\n",
    "    \n",
    "    for ff in list(itertools.combinations(X_train.columns, num_features)):\n",
    "        #+1 because it will be used with the row of ones\n",
    "        idx = [X_train.columns.get_loc(ii)+1 for ii in ff]; \n",
    "        idx.insert(0,0);\n",
    "        X_small = X_b[:,idx];\n",
    "\n",
    "        b_man  = inv(X_small.T.dot(X_small)).dot(X_small.T).dot(y_train);\n",
    "        lr = LinearRegression();\n",
    "        #print(X_small.shape)\n",
    "        lr.fit(X_small[:,1:], y_train);\n",
    "        y_pred_sk  = lr.predict(X_small[:,1:]);\n",
    "        y_pred_man = X_small.dot(b_man);\n",
    "        rss_sk  = np.sum(np.square(y_train-y_pred_sk));\n",
    "        rss_man = np.sum(np.square(y_train-y_pred_man));\n",
    "        \n",
    "        errors[\"features\"].append(ff);\n",
    "        errors['errors'].append(rss_man);\n",
    "        if rss_man < err:\n",
    "            err = rss_man;\n",
    "            best_subset['names']   = ff;\n",
    "            best_subset['indexes'] = idx; #wrt X_with_bias_coeffs\n",
    "            best_subset['coeffs']  = b_man;\n",
    "            best_subset['err']     = rss_man;\n",
    "            best_subset['all_errors']     = errors;\n",
    "            best_subset['skl_model'] = lr;\n",
    "            \n",
    "      \n",
    "    best_models[\"error_sequence\"].append(best_subset['err']);\n",
    "    best_models[num_features] = best_subset;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[()]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(itertools.combinations([1,2,3], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got scalar array instead:\narray=nan.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-208-c6c3080f7068>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_submodel_sk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-208-c6c3080f7068>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, num_features, isItwithoutBias)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mX_small\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_no_bias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mtemp_pipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mtemp_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0;31m#probably separate scaler for transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0my_pred_sk\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtemp_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_small\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mmse_sk\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred_sk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    228\u001b[0m                 Xt, fitted_transformer = fit_transform_one_cached(\n\u001b[1;32m    229\u001b[0m                     \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                     **fit_params_steps[name])\n\u001b[0m\u001b[1;32m    231\u001b[0m                 \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, **fit_params)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    667\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n\u001b[1;32m    668\u001b[0m                         \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                         force_all_finite='allow-nan')\n\u001b[0m\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;31m# Even in the case of `with_mean=False`, we update the mean anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    543\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    546\u001b[0m             \u001b[0;31m# If input is 1D raise error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got scalar array instead:\narray=nan.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "import itertools;\n",
    "from sklearn.pipeline import Pipeline;\n",
    "from sklearn.preprocessing import StandardScaler;\n",
    "from sklearn.base import clone;\n",
    "class error_sequence:\n",
    "    def __init__(self):\n",
    "        self.errors = None;\n",
    "        self.names  = None;        \n",
    "    def __init__(self, errors, sequence):\n",
    "        self.errors = (errors, sequence);\n",
    "        \n",
    "\n",
    "class best_submodel_abstract:\n",
    "    def __init__(self):\n",
    "        self._standardInit();\n",
    "        #later let user choose type\n",
    "        self.pipeline = Pipeline([\n",
    "                ('Scaler', StandardScaler()), \n",
    "                ('LinearRegression', LinearRegression())]);  \n",
    "    \n",
    "    def get_scaler(self):\n",
    "        return self.pipeline.named_steps['Scaler'];\n",
    "    def get_model(self):\n",
    "        return self.pipeline.named_steps['LinearRegression'];\n",
    "        \n",
    "        \n",
    "    def _standardInit(self):\n",
    "        self.X_small = None;\n",
    "        self.num_features  = None;\n",
    "        self.feature_names = None;\n",
    "        self.indexes       = None; #wrt X_with_bias_coeffs\n",
    "        self.best_coeffs   = None;\n",
    "        self.err           = None;\n",
    "        self.all_errors    = None;\n",
    "        self.skl_model     = None;   \n",
    "        \n",
    "    def _removeBias(self, X, num_features, isItwithoutBias=True):\n",
    "        self.num_features = num_features;\n",
    "        if (not isItwithoutBias):\n",
    "            # scikit will be used and LinearRegression does not want the column of 1s\n",
    "            print(\"removing bias\");\n",
    "            X_small = X[:,1:];\n",
    "        else:\n",
    "            X_small = X;\n",
    "        return X_small;\n",
    "    \n",
    "    def fit(self, X, y,num_features, isItwithoutBias=True):\n",
    "        return\n",
    "\n",
    "class best_submodel_sk(best_submodel_abstract):\n",
    "    def __init__(self):\n",
    "        super(best_submodel_sk, self).__init__();\n",
    "       \n",
    "    def _update_best_model(self, pipeline, subset, mse):\n",
    "        self.pipeline = pipeline;\n",
    "        self.best_subset     = ff;\n",
    "        self.best_subset_idx = ff; #wrt X_with_bias_coeffs\n",
    "        self.best_error      = mse;\n",
    "        self.all_errors      = error_sequence(tuple(errors['errors']),\n",
    "                                              tuple(errors[\"features\"]));\n",
    "        self.model           = self.get_model();\n",
    "        self.scaler          = self.get_scaler();\n",
    "        return \n",
    "    \n",
    "    def fit(self, X, y, num_features, isItwithoutBias=True):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            column_names = list(X.columns)\n",
    "            X = X.values;\n",
    "        X_no_bias   = super()._removeBias(X,num_features, isItwithoutBias);\n",
    "        self.errors = {\"features\":list(), \"errors\":list()};\n",
    "        err = np.infty;\n",
    "        all_idx = [i for i in range(X_no_bias.shape[1])];\n",
    "        errors = {\"features\":list(), \"errors\":list()};\n",
    "        if num_features==0:\n",
    "            X_small = np.ones((X_no_bias.shape[0],1));\n",
    "            temp_pipe = clone(self.pipeline); \n",
    "            temp_pipe.fit(X_small, y); #probably separate scaler for transform\n",
    "            y_pred_sk  = temp_pipe.predict(X_small);\n",
    "            mse_sk     = mean_squared_error(y_train,y_pred_sk);\n",
    "            errors[\"features\"].append(0);\n",
    "            errors['errors'].append(mse_sk);\n",
    "            self._update_best_model(temp_pipe, 0, mse_sk)\n",
    "            return;\n",
    "        elif num_features>X_no_bias.shape[1]:\n",
    "            num_features=X_no_bias.shape[1];\n",
    "        for ff in list(itertools.combinations(all_idx, num_features)):\n",
    "            #print(ff)\n",
    "            X_small = X_no_bias[:,ff]; \n",
    "            # copy to have the same type instead of declaring\n",
    "            temp_pipe = clone(self.pipeline); \n",
    "            temp_pipe.fit(X_small, y); #probably separate scaler for transform\n",
    "            y_pred_sk  = temp_pipe.predict(X_small);\n",
    "            mse_sk     = mean_squared_error(y_train,y_pred_sk);\n",
    "            self.all_errors      = error_sequence(tuple(errors['errors']),\n",
    "                                                    tuple(errors[\"features\"]));\n",
    "            if mse_sk < err:\n",
    "                self._update_best_model(temp_pipe, ff, mse_sk);\n",
    "\n",
    "l = best_submodel_sk();\n",
    "l.fit(X_train, y_train, 0)\n",
    "l.model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward stepwise selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67, 9)\n"
     ]
    }
   ],
   "source": [
    "#sklearn does not support\n",
    "import itertools;\n",
    "from scipy.linalg import inv\n",
    "\n",
    "\n",
    "print(X_b.shape)\n",
    "#intercept only\n",
    "X_small = np.copy(X_b[:,0]).reshape(-1,1); #np.ones\n",
    "b_man  = scipy.linalg.inv(X_small.T.dot(X_small)).dot(X_small.T.dot(y_train));\n",
    "lr = LinearRegression();\n",
    "lr.fit(X_small, y_train);\n",
    "y_pred_sk  = lr.predict(X_small);\n",
    "y_pred_man = X_small.dot(b_man);\n",
    "rss_sk  = np.sum(np.square(y_train-y_pred_sk));\n",
    "rss_man = np.sum(np.square(y_train-y_pred_man.reshape(y_train.shape)));\n",
    "best_fw_models = {num_features : dict()};\n",
    "best_fw_subset = dict();\n",
    "best_fw_subset['names']      = [\"intercept\",];\n",
    "best_fw_subset['indexes']    = [0]; #wrt X_with_bias_coeffs\n",
    "best_fw_subset['coeffs']     = b_man;\n",
    "best_fw_subset['err']        = rss_man;\n",
    "best_fw_subset['all_errors'] = [];\n",
    "best_fw_subset['skl_model']  = lr;\n",
    "best_fw_models[0] = best_fw_subset.copy();\n",
    "best_fw_models[\"error_sequence\"] = list();\n",
    "best_fw_models[\"error_sequence\"].append(best_fw_subset['err']);\n",
    "best_fw_subset['indexes'] = [0,];\n",
    "l_feat = list(X_train.columns);\n",
    "for num_features in np.arange(1,len(X_train.columns)+1):\n",
    "    #print(best_fw_subset['coeffs'])\n",
    "    err = np.infty;\n",
    "    errors = {\"features\":list(), \"errors\":list()};\n",
    "    best_fw_subset['names'].append('')\n",
    "    best_fw_subset['indexes'].append(np.infty);\n",
    "    for ff in l_feat:\n",
    "        idx = best_fw_subset['indexes'][:-1];\n",
    "        idx.append(X_train.columns.get_loc(ff)+1);\n",
    "        X_small = X_b[:,idx];\n",
    "        b_man = inv(X_small.T.dot(X_small)).dot(X_small.T).dot(y_train);\n",
    "        lr = LinearRegression();\n",
    "        lr.fit(X_small[:,1:], y_train);\n",
    "        y_pred_sk  = lr.predict(X_small[:,1:]);\n",
    "        y_pred_man = X_small.dot(b_man);\n",
    "\n",
    "        rss_sk  = np.sum(np.square(y_train-y_pred_sk));\n",
    "        rss_man = np.sum(np.square(y_train-y_pred_man));\n",
    "        errors[\"features\"].append(ff);\n",
    "        errors['errors'].append(rss_man);\n",
    "        if rss_man < err:\n",
    "            err = rss_man;\n",
    "            best_fw_subset['names'][-1]   = ff;\n",
    "            best_fw_subset['indexes'][-1] = idx[-1]; #wrt X_with_bias_coeffs\n",
    "            best_fw_subset['coeffs']      = b_man.copy();\n",
    "            best_fw_subset['err']         = rss_man;\n",
    "            best_fw_subset['all_errors']  = errors;\n",
    "            best_fw_subset['skl_model']   = lr;\n",
    "\n",
    "    l_feat.remove(best_fw_subset['names'][-1]);\n",
    "    best_fw_models[\"error_sequence\"].append(best_fw_subset['err']);\n",
    "    best_fw_models[num_features] = best_fw_subset.copy();\n",
    "    #print(num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orthogonal dependent stepwise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97, 9)\n",
      "(97, 1)\n"
     ]
    }
   ],
   "source": [
    "#sklearn does not support\n",
    "from scipy.linalg import inv\n",
    "\n",
    "num_features = X_b.shape[1]-1;\n",
    "print(X_b.shape)\n",
    "#intercept only\n",
    "X_small = np.copy(X_b[:,0]).reshape(-1,1); #np.ones\n",
    "b_man  = scipy.linalg.inv(X_small.T.dot(X_small)).dot(X_small.T.dot(y_train));\n",
    "lr = LinearRegression();\n",
    "lr.fit(X_small, y_train);\n",
    "y_pred_sk  = lr.predict(X_small);\n",
    "print(X_small.shape)\n",
    "y_pred_man = X_small.dot(b_man);\n",
    "rss_sk  = np.sum(np.square(y_train-y_pred_sk));\n",
    "rss_man = np.sum(np.square(y_train-y_pred_man.reshape(y_train.shape)));\n",
    "best_fw_orth_dep_models = {num_features : dict()};\n",
    "best_fw_orth_dep_subset = dict();\n",
    "best_fw_orth_dep_subset['names']      = [\"intercept\",];\n",
    "best_fw_orth_dep_subset['indexes']    = [0]; #wrt X_with_bias_coeffs\n",
    "best_fw_orth_dep_subset['coeffs']     = b_man;\n",
    "best_fw_orth_dep_subset['err']        = rss_man;\n",
    "best_fw_orth_dep_subset['all_errors'] = [];\n",
    "best_fw_orth_dep_subset['skl_model']  = lr;\n",
    "best_fw_orth_dep_models[0] = best_fw_orth_dep_subset.copy();\n",
    "best_fw_orth_dep_models[\"error_sequence\"] = list();\n",
    "best_fw_orth_dep_models[\"error_sequence\"].append(best_fw_orth_dep_subset['err']);\n",
    "best_fw_orth_dep_subset['indexes'] = [0,];\n",
    "l_feat = list(X_train.columns);\n",
    "y_new  = y_train;\n",
    "for num_features in np.arange(1,len(X_train.columns)+1):\n",
    "    err = np.infty;\n",
    "    errors = {\"features\":list(), \"errors\":list()};\n",
    "    best_fw_orth_dep_subset['names'].append('')\n",
    "    best_fw_orth_dep_subset['indexes'].append(np.infty);\n",
    "    for ff in l_feat:\n",
    "        idx = best_fw_orth_dep_subset['indexes'][:-1];\n",
    "        idx.append(X_train.columns.get_loc(ff)+1);\n",
    "        X_small = X_b[:,idx];\n",
    "        b_man = inv(X_small.T.dot(X_small)).dot(X_small.T).dot(y_train);\n",
    "        lr = LinearRegression();\n",
    "        lr.fit(X_small[:,1:], y_train);\n",
    "        y_pred_sk  = lr.predict(X_small[:,1:]);\n",
    "        y_pred_man = X_small.dot(b_man);\n",
    "        rss_sk  = np.sum(np.square(y_train-y_pred_sk));\n",
    "        rss_man = np.sum(np.square(y_train-y_pred_man));\n",
    "        errors[\"features\"].append(ff);\n",
    "        errors['errors'].append(rss_man);\n",
    "        if rss_man < err:\n",
    "            err = rss_man;\n",
    "            #print(best_fw_subset['names'])\n",
    "            best_fw_orth_dep_subset['names'][-1]   = ff;\n",
    "            best_fw_orth_dep_subset['indexes'][-1] = idx[-1]; #wrt X_with_bias_coeffs\n",
    "            best_fw_orth_dep_subset['coeffs']      = b_man;\n",
    "            best_fw_orth_dep_subset['err']         = rss_man;\n",
    "            best_fw_orth_dep_subset['all_errors']  = errors;\n",
    "            best_fw_orth_dep_subset['skl_model']   = lr;\n",
    "\n",
    "    #here is the difference from normal forward stepwise\n",
    "    y_new = y_new - y_pred;\n",
    "    l_feat.remove(best_fw_orth_dep_subset['names'][-1]);\n",
    "    best_fw_orth_dep_models[\"error_sequence\"].append(best_fw_orth_dep_subset['err']);\n",
    "    best_fw_orth_dep_models[num_features] = best_fw_orth_dep_subset.copy();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.47838688, 0.61657908, 0.28204449, 0.27415833])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models[3][\"coeffs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QR forward stepwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97, 9)\n",
      "[ 2.47838688  0.63785585  0.25069461  0.29443703  0.14609653 -0.12180107]\n"
     ]
    }
   ],
   "source": [
    "#sklearn does not support\n",
    "from scipy.linalg import inv\n",
    "import scipy.linalg\n",
    "import scipy.linalg\n",
    "\n",
    "print(X_b.shape)\n",
    "\n",
    "num_features = X_b.shape[1]-1;\n",
    "l_feat = list(X_train.columns);\n",
    "y_new  = y_train;\n",
    "\n",
    "q1  = X_b[:,0];\n",
    "q1  = (q1/scipy.linalg.norm(q1));\n",
    "q1.reshape(-1,1);\n",
    "r   = q1.dot(X_b[:,0]);\n",
    "Q   = q1.reshape(-1,1);\n",
    "R   = np.array(r).reshape(1,1);\n",
    "y_hat = Q.dot(Q.T).dot(y_train);\n",
    "y_new = y_new-y_hat;\n",
    "rss_man = np.sum(np.square(y_train-y_hat));\n",
    "b_man = np.linalg.inv(R).dot(Q.T).dot(y_train);\n",
    "selected_idx = list();\n",
    "selected_idx.append(0);\n",
    "best_fw_qr_models = {num_features : dict()};\n",
    "best_fw_qr_subset = dict();\n",
    "best_fw_qr_subset['names']          = [\"intercept\",];\n",
    "best_fw_qr_subset['indexes']        = [0]; #wrt X_with_bias_coeffs\n",
    "best_fw_qr_subset['coeffs']         = b_man.copy();\n",
    "best_fw_qr_subset['err']            = rss_man;\n",
    "best_fw_qr_subset['all_errors']     = [];\n",
    "best_fw_qr_subset['skl_model']      = lr;\n",
    "best_fw_qr_subset['indexes']        = [0,];\n",
    "best_fw_qr_models[0]                = best_fw_qr_subset.copy();\n",
    "best_fw_qr_models[\"error_sequence\"] = list();\n",
    "best_fw_qr_models[\"error_sequence\"].append(best_fw_qr_subset['err']);\n",
    "for num_features in np.arange(1,len(X_train.columns)+1):\n",
    "    best_ = -np.infty;\n",
    "    errors = {\"features\":list(), \"errors\":list()};\n",
    "    #print(best_fw_qr_subset['names'])\n",
    "    best_fw_qr_subset['names'].append('');\n",
    "    best_fw_qr_subset['indexes'].append(np.infty);\n",
    "    #print(best_fw_qr_models[0]['coeffs'])\n",
    "    for ff in l_feat:\n",
    "        idx = X_train.columns.get_loc(ff)+1;\n",
    "        x_k = X_b[:,idx].reshape(-1,1);\n",
    "        residual = x_k - Q.dot(Q.T.dot(x_k));#x_k.T.dot(Q).dot(Q.T).T;\n",
    "        q_new = residual/scipy.linalg.norm(residual);\n",
    "        y_q_prod_sq = np.square(y_new.T.dot(q_new));\n",
    "        Q_temp = np.concatenate((Q,q_new), axis=1);\n",
    "        R_temp = np.concatenate((R,np.zeros((1,R.shape[1]))), axis=0);\n",
    "        R_temp = np.concatenate((R_temp, x_k.T.dot(Q_temp).T), axis =1)\n",
    "        y_hat = Q_temp.dot(Q_temp.T).dot(y_train);\n",
    "        rss_man = np.sum(np.square(y_train-y_hat));\n",
    "        errors[\"features\"].append(ff);\n",
    "        errors['errors'].append(rss_man);\n",
    "        if (y_q_prod_sq> best_):\n",
    "            q_best = q_new;\n",
    "            r_best = residual;\n",
    "            best_ = y_q_prod_sq;\n",
    "            best_ff = ff;\n",
    "            best_fw_qr_subset['err'] = rss_man;\n",
    "            x_best = x_k;\n",
    "\n",
    "    Q = np.concatenate((Q,q_best), axis=1);\n",
    "    R = np.concatenate((R,np.zeros((1,R.shape[1]))), axis=0);\n",
    "#    R = np.concatenate((R,x_k.T.dot(Q)), axis =1)\n",
    "    R = np.concatenate((R,Q.T.dot(x_best)), axis=1)\n",
    "    #here is the difference from normal forward stepwise\n",
    "    y_hat = Q.dot(Q.T).dot(y_train);\n",
    "    y_new = y_new - y_hat;#\n",
    "    b_man = np.linalg.inv(R.T.dot(R)).dot(R.T).dot(Q.T).dot(y_train);\n",
    "    best_fw_qr_subset['names'][-1]   = best_ff;\n",
    "    best_fw_qr_subset['indexes'][-1] = idx; #wrt X_with_bias_coeffs\n",
    "    best_fw_qr_subset['coeffs']      = b_man.copy();\n",
    "    best_fw_qr_subset['all_errors']  = errors;\n",
    "    l_feat.remove(best_ff);\n",
    "    best_fw_qr_models[\"error_sequence\"].append(best_fw_qr_subset['err']);\n",
    "    best_fw_qr_models[num_features] = best_fw_qr_subset.copy();\n",
    "print(best_fw_qr_models[5]['coeffs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.47838688,  0.63785585,  0.25069461,  0.29443703,  0.14609653,\n",
       "       -0.12180107])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_fw_qr_models[5]['coeffs']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.47838688,  0.63785585,  0.25069461, -0.12180107,  0.14609653,\n",
       "        0.29443703])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models[5]['coeffs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.8488578]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(r).reshape(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.concatenate((R,np.zeros((1,R.shape[1]))), axis=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.84885780e+00,  2.87141217e-16, -4.33133049e-15,\n",
       "        -3.17034112e-15, -6.08254021e-16,  4.20630455e-15,\n",
       "         9.69436548e-16,  3.00549941e-15, -2.69188418e-15],\n",
       "       [ 0.00000000e+00,  9.84885780e+00,  2.76281518e+00,\n",
       "         5.30700780e+00,  2.69363339e-01,  2.21599182e+00,\n",
       "         4.27097934e+00,  6.65103693e+00,  4.25881409e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  9.45340427e+00,\n",
       "         4.33763147e-02,  4.45928730e+00,  2.92282306e+00,\n",
       "        -1.46678311e-01, -2.55514626e-01, -6.61005602e-01],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         8.29661296e+00, -1.19925263e+00, -5.71603672e-02,\n",
       "         2.61938946e+00,  3.61662807e+00,  1.02536997e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  8.69505568e+00,  2.33107966e+00,\n",
       "         1.17947110e+00,  3.45733668e-01,  1.21663471e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  8.83794580e+00,\n",
       "         1.71391081e+00, -2.49747212e-01,  1.78769239e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         8.21872116e+00,  2.84244030e+00,  5.77507140e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  5.59973653e+00,  2.40413429e-01],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  6.26808569e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backword stepwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97, 9) (9,)\n",
      "127.91765888525164\n"
     ]
    }
   ],
   "source": [
    "#sklearn does not support\n",
    "import itertools;\n",
    "from scipy.linalg import inv\n",
    "num_features = X_b.shape[1]-1;\n",
    "#intercept only\n",
    "X_small = X_b.copy();#np.copy(X_b[:,0]).reshape(-1,1); #np.ones\n",
    "b_man  = scipy.linalg.inv(X_small.T.dot(X_small)).dot(X_small.T.dot(y_train));\n",
    "lr = LinearRegression();\n",
    "lr.fit(X_small, y_train);\n",
    "y_pred_sk  = lr.predict(X_small);\n",
    "print(X_small.shape, b_man.shape)\n",
    "y_pred_man = X_small.dot(b_man.reshape(-1,1));\n",
    "rss_sk  = np.sum(np.square(y_train-y_pred_sk));\n",
    "rss_man = np.sum(np.square(y_train-y_pred_man.reshape(y_train.shape)));\n",
    "best_bw_models = {num_features : dict()};\n",
    "best_bw_subset = dict();\n",
    "best_bw_subset['names']      = list(X_train.columns);\n",
    "best_bw_subset['indexes']    = [ii for ii in np.arange(0,num_features+1)]; #wrt X_with_bias_coeffs\n",
    "best_bw_subset['coeffs']     = b_man;\n",
    "best_bw_subset['err']        = rss_man;\n",
    "best_bw_subset['all_errors'] = [];\n",
    "best_bw_subset['skl_model']  = lr;\n",
    "best_bw_models[num_features] = best_bw_subset.copy();\n",
    "best_bw_models[\"error_sequence\"] = list();\n",
    "best_bw_models[\"z_scores\"] = list();\n",
    "best_bw_models[\"error_sequence\"].append(best_fw_subset['err']);\n",
    "#best_bw_subset['indexes'] = [np.arange(0,num_features+1)];\n",
    "orig_num_features = num_features;\n",
    "indexes = [ii for ii in range(0,10)];\n",
    "for num_features in np.arange(1,len(X_train.columns)+1):\n",
    "    XX = scipy.linalg.inv(X_small.T.dot(X_small));\n",
    "    z_score_worst = np.infty;\n",
    "    errors = {\"features\":list(), \"errors\":list()};\n",
    "    normalized_rss = rss_man/(len(X_train-orig_num_features+num_features -1))\n",
    "    \n",
    "    for k,ff in enumerate(best_bw_subset['names']):\n",
    "        z_score = b_man[k]/(np.sqrt(normalized_rss*XX[k,k]));\n",
    "        best_bw_models[\"z_scores\"].append(z_scores);\n",
    "        if abs(z_score) < z_score_worst:\n",
    "            z_score_worst = z_score;\n",
    "            k_worst = k;\n",
    "            ff_worst = ff;\n",
    "            best_bw_subset['err'] = rss_man;\n",
    "\n",
    "    best_bw_subset['names'].remove(ff_worst);\n",
    "    best_bw_subset['indexes'].remove(X_train.columns.get_loc(ff_worst)+1);#wrt X_with_bias_coeffs\n",
    "    y_pred_man = X_small.dot(b_man);   \n",
    "    rss_man = np.sum(np.square(y_train-y_pred_man));\n",
    "    X_small = X_b[:, best_bw_subset['indexes']];\n",
    "    b_man  = scipy.linalg.inv(X_small.T.dot(X_small)).dot(X_small.T.dot(y_train));\n",
    "    best_bw_subset['coeffs'] = b_man.copy();\n",
    "    best_bw_subset['err']    = rss_man;\n",
    "    best_bw_models[orig_num_features-num_features] = best_bw_subset.copy();\n",
    "    best_bw_models[\"error_sequence\"].insert(0, best_bw_subset[\"err\"]);\n",
    "    \n",
    "\n",
    "\n",
    "#Now it contains only 0\n",
    "\n",
    "X_small = X_b[:, best_bw_subset['indexes']];\n",
    "b_man  = scipy.linalg.inv(X_small.T.dot(X_small)).dot(X_small.T.dot(y_train));\n",
    "y_pred_man = X_small.dot(b_man);   \n",
    "rss_man = np.sum(np.square(y_train-y_pred_man));\n",
    "print(rss_man)\n",
    "best_bw_subset['err']    = rss_man;\n",
    "best_bw_models[\"error_sequence\"].insert(0, best_bw_subset[\"err\"]);\n",
    "XX = scipy.linalg.inv(X_small.T.dot(X_small));\n",
    "errors = {\"features\":list(), \"errors\":list()};\n",
    "normalized_rss = rss_man/(len(X_train-orig_num_features+num_features -1))\n",
    "z_score = b_man[k]/(np.sqrt(normalized_rss*XX[k,k]));\n",
    "best_bw_subset['names'] = ['intercept',]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.47838688,  0.70243067,  0.32512188, -0.12620984,  0.18030652])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_bw_models[4][\"coeffs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.47838688, 0.61967302, 0.22845699, 0.29055615, 0.11344257])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_fw_models[4][\"coeffs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stagewise regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97, 9)\n",
      "0.8434274382607599\n",
      "0.8434274382607599\n",
      "[0.26100874]\n",
      "[0.26100874]\n",
      "[0.15519087]\n",
      "[0.15519087]\n",
      "[-0.15684236]\n",
      "[-0.15684236]\n",
      "[0.08818995]\n",
      "[0.08818995]\n",
      "[-0.09316011]\n",
      "[-0.09316011]\n",
      "[0.11129984]\n",
      "[0.11129984]\n",
      "[0.06466917]\n",
      "[0.06466917]\n",
      "[-0.06737883]\n",
      "[-0.06737883]\n",
      "[0.04535345]\n",
      "[0.04535345]\n",
      "[-0.04331858]\n",
      "[-0.04331858]\n",
      "[-0.02499753]\n",
      "[-0.02499753]\n",
      "[0.03693757]\n",
      "[0.03693757]\n",
      "[-0.02350057]\n",
      "[-0.02350057]\n",
      "[0.02171228]\n",
      "[0.02171228]\n",
      "[0.01954552]\n",
      "[0.01954552]\n",
      "[-0.02046127]\n",
      "[-0.02046127]\n",
      "[0.02127011]\n",
      "[0.02127011]\n",
      "[-0.01473005]\n",
      "[-0.01473005]\n",
      "[-0.00906994]\n",
      "[-0.00906994]\n",
      "[0.01479569]\n",
      "[0.01479569]\n",
      "[-0.00995915]\n",
      "[-0.00995915]\n",
      "[0.00901681]\n",
      "[0.00901681]\n",
      "[0.00547287]\n",
      "[0.00547287]\n",
      "[-0.00460382]\n",
      "[-0.00460382]\n",
      "[0.00738321]\n",
      "[0.00738321]\n",
      "[-0.00496972]\n",
      "[-0.00496972]\n",
      "[0.00334517]\n",
      "[0.00334517]\n",
      "[-0.00369254]\n",
      "[-0.00369254]\n",
      "[0.0031471]\n",
      "[0.0031471]\n",
      "[-0.00229807]\n",
      "[-0.00229807]\n",
      "[0.00306234]\n",
      "[0.00306234]\n",
      "[-0.00162514]\n",
      "[-0.00162514]\n",
      "[-0.0013691]\n",
      "[-0.0013691]\n",
      "[0.00162386]\n",
      "[0.00162386]\n",
      "[0.0011997]\n",
      "[0.0011997]\n",
      "[-0.00111989]\n",
      "[-0.00111989]\n",
      "[0.00101244]\n",
      "[0.00101244]\n",
      "[-0.0008496]\n"
     ]
    }
   ],
   "source": [
    "#sklearn does not support\n",
    "import itertools;\n",
    "from scipy.linalg import inv\n",
    "\n",
    "\n",
    "print(X_b.shape)\n",
    "#intercept only\n",
    "X_small = np.copy(X_b[:,0]).reshape(-1,1); #np.ones\n",
    "b_man  = scipy.linalg.inv(X_small.T.dot(X_small)).dot(X_small.T.dot(y_train));\n",
    "\n",
    "y_pred_man = X_small.dot(b_man);\n",
    "rss_man = np.sum(np.square(y_train-y_pred_man.reshape(y_train.shape)));\n",
    "best_sw_models = dict();\n",
    "\n",
    "residual = y_train - y_pred_man;\n",
    "best_sw_models['coeffs'] = np.concatenate((b_man.reshape(1,1), np.zeros((X_train.shape[1],1))), axis=0);\n",
    "#best_sw_models['error_sequence'] = list();\n",
    "#best_sw_models['error_sequence'].append(residual);\n",
    "#best_sw_models['coeffs_history'] = list();\n",
    "#best_sw_models['coeffs_history'].append(b_man);\n",
    "\n",
    "#best_sw_models['coeffs_updated'] = list();\n",
    "#best_sw_models['coeffs_updated'].append(0);\n",
    "count = 0;\n",
    "\n",
    "l_feat = list(X_train.columns);\n",
    "while 1:\n",
    "    #print(residual)\n",
    "    max_corr = 0;\n",
    "    for ff in l_feat:\n",
    "        idx = X_train.columns.get_loc(ff)+1;\n",
    "        x_k = X_b[:,idx];\n",
    "        corr = x_k.dot(residual)/len(x_k);\n",
    "        if abs(corr) > abs(max_corr):\n",
    "           max_idx = idx;\n",
    "           max_corr = corr;\n",
    "    print(max_corr)\n",
    "    if abs(max_corr)<0.001 or count>10000:\n",
    "        break;\n",
    "    print(max_corr)\n",
    "    x_most_corr = X_b[:, max_idx];\n",
    "    b_most_corr = (x_most_corr.T.dot(x_most_corr))**(-1)*(x_most_corr.T.dot(residual));\n",
    "    best_sw_models['coeffs'][max_idx] = best_sw_models['coeffs'][max_idx] + b_most_corr;\n",
    "    y_hat = X_b.dot(best_sw_models['coeffs']);\n",
    "    residual = y_train.values.reshape(-1,1) - y_hat;\n",
    "    #best_sw_models['error_sequence'].append(residual);\n",
    "    count += 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.47838688],\n",
       "       [ 0.66196462],\n",
       "       [ 0.26415584],\n",
       "       [-0.15652642],\n",
       "       [ 0.13968469],\n",
       "       [ 0.31190695],\n",
       "       [-0.14510743],\n",
       "       [ 0.0343617 ],\n",
       "       [ 0.12512751]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_sw_models['coeffs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.47838688,  0.6617092 ,  0.26510309, -0.15737767,  0.13958604,\n",
       "        0.31369926, -0.14751935,  0.03536545,  0.1250701 ])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models[8]['coeffs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
