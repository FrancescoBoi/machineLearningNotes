\section{Custom models and training with Tensorflow}
\subsection{Using Tensorflow as numpy}
A tensor is usually a multidimensional array (exactly like a NumPy \cd+ndarray+) having a shape and type, but it can also hold a scalar. You can easily create a tensor using \cd+tf.constant()+. The \cd+@+ operator is for matrix multiplication: \cd+t @ tf.transpose(t)+ is equivalent to calling \cd+tf.matmul()+.

Type conversions can significantly hurt performance, and they can easily go unnoticed when they are done automatically. To avoid this, TensorFlow does not perform any type conversions automatically: it just raises an exception if you try to execute an operation on tensors with incompatible types. For example, you cannot add a float tensor and an integer tensor, and you cannot even add a 32-bit float and a 64-bit float

A \cd+tf.Variable+ acts much like a constant tensor: you can perform the same operations with it, it plays nicely with NumPy as well, and it is just as picky with types. But it can also be modified in place using the \cd+assign()+ method (or '\cd+assign_add()+ or \cd+assign_sub()+ which increment or decrement the variable by the given value). You can also modify individual cells (or slices), using the cell's (or slice's) \cd+assign()+ method (direct item assignment will not work), or using the \cd+scatter_update()+ or \cd+scatter_nd_update()+ methods

\subsection{Customising  models and training algorithms}
\subsubsection{Customising the loss function}
Suppose one wants to use the Huber loss instead of the MSE. Huber loss is not currently part of the official Keras API but it is available in \cd+tf.keras+. But let's pretend it's not there and one has to implement it:
\begin{lstlisting}
def huber_fn(y_true, y_pred):
	error = y_true - y_pred
	is_small_error = tf.abs(error) < 1
	squared_loss = tf.square(error) / 2
	linear_loss = tf.abs(error) - 0.5
	return tf.where(is_small_error, squared_loss, linear_loss)
\end{lstlisting}
For better performance, you should use a vectorized implementation, as in this example. Moreover, if you want to benefit from TensorFlow's graph features, you should use only TensorFlow operations. 
It is also preferable to return a tensor containing one loss per instance, rather than returning the mean loss. This way, Keras can apply class weights or sample weights when requested.

To use it when compiling the model one has to:
\begin{lstlisting}
model.compile(loss=huber_fn, optimizer="nadam")
model.fit(X_train, y_train, [...])
\end{lstlisting}
\subsection{Saving a model}
Saving a model containing a custom loss function actually works fine, as Keras just saves the name of the function. However, whenever you load it, you need to provide a dictionary that maps the function name to the actual function. More generally, when you load a model containing custom objects, you need to map the names to the objects:
\begin{lstlisting}
model = keras.models.load_model("my_model_with_a_custom_loss.h5", custom_objects={"huber_fn": huber_fn})
\end{lstlisting}
However the another value for the threshold might be desired. A better approach is to subclass the \cd+keras.losses.Loss+ class:
\begin{lstlisting}
class HuberLoss(keras.losses.Loss):
	def __init__(self, threshold=1.0, **kwargs):
    	self.threshold = threshold
	super().__init__(**kwargs) 
	
	def call(self, y_true, y_pred):
		error = y_true - y_pred
		is_small_error = tf.abs(error) < self.threshold
		squared_loss = tf.square(error) / 2
		linear_loss = self.threshold * tf.abs(error) - self.threshold**2 / 2 return tf.where(is_small_error, squared_loss, linear_loss)
	
	def get_config(self):
		base_config = super().get_config()
		return {**base_config, "threshold": self.threshold}
\end{lstlisting}
When you save the model, the threshold will be saved along with it, and when you load the model you just need to map the class name to the class itself:
\begin{lstlisting}
model = keras.models.load_model("my_model_with_a_custom_loss_class.h5", custom_objects={"HuberLoss": HuberLoss})
\sub
\end{lstlisting}
\subsubsection{Customising the activation function}
\begin{lstlisting}
def my_softplus(z): # return value is just tf.nn.softplus(z) 
	return tf.math.log(tf.exp(z) + 1.0)

def my_glorot_initializer(shape, dtype=tf.float32):
	stddev = tf.sqrt(2. / (shape[0] + shape[1]))
	return tf.random.normal(shape, stddev=stddev, dtype=dtype)

def my_l1_regularizer(weights):
	return tf.reduce_sum(tf.abs(0.01 * weights))
def my_positive_weights(weights): # return value is just tf.nn.relu(weights)
	return tf.where(weights < 0., tf.zeros_like(weights), weights)

layer = keras.layers.Dense(30, activation=my_softplus, kernel_initializer=my_glorot_initializer, kernel_regularizer=my_l1_regularizer, kernel_constraint=my_positive_weights)
\end{lstlisting}
If a function has some hyperparameters that need to be saved along with the model, then you will want to subclass the appropriate class, such as \cd+keras.regularizers.Regularizer+, \cd+keras.constraints.Constraint+, \cd+keras.initializers.Initializer+ or \cd+keras.layers.Layer+.
\begin{lstlisting}
class MyL1Regularizer(keras.regularizers.Regularizer): 
	def __init__(self, factor):
		self.factor = factor 
	
	def __call__(self, weights):
		return tf.reduce_sum(tf.abs(self.factor * weights))
	
	def get_config(self):
			return {"factor": self.factor}
\end{lstlisting}

\subsubsection{Custom metrics}
Losses and metrics are conceptually not the same thing: losses are used by Gradient Descent to train a model, so they must be differentiable (at least where they are evaluated) and their gradients should not be $0$ everywhere. Plus, it's okay if they are not easily interpretable by humans (e.g. cross-entropy). In contrast, metrics are used to evaluate a model, they must be more easily interpretable, and they can be non- differentiable or have 0 gradients everywhere (e.g., accuracy). That said, in most cases, defining a custom metric function is exactly the same as defining a custom loss function.

Suppose the model made 5 positive predictions in the first batch, $4$ of which were correct: that's $80\%$ precision. Then suppose the model made $3$ positive predictions in the second batch, but they were all incorrect: that's $0\%$ precision for the second batch. If you just compute the mean of these two precisions, you get $40\%$. But wait a second, this is not the model's precision over these two batches! Indeed, there were a total of 4 true positives ($4 + 0$) out of $8$ positive predictions ($5 + 3$), so the overall precision is $50\%$, not $40\%$. What we need is an object that can keep track of the number of true positives and the number of false positives, and compute their ratio when requested. This is precisely what the \cd+keras.metrics.Precision+ class does:

%\begin{lstlisting}
%>>> precision = keras.metrics.Precision()
%>>> precision([0, 1, 1, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 1]) <tf.Tensor: id=581729, shape=(), dtype=float32, numpy=0.8>
%>>> precision([0, 1, 0, 0, 1, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0, 0]) <tf.Tensor: id=581780, shape=(), dtype=float32, numpy=0.5>
%\end{lstlisting}
At any point, we can call the \cd+result()+ method to get the current value of the metric. We can also look at its \cd+variables+ (tracking the number of true and false positives) using the variables attribute, and reset these variables using the \cd+reset_states()+ method. If you need to create such a streaming metric, you can just create a subclass of the \cd+keras.metrics.Metric+ class. 

\begin{lstlisting}
class HuberMetric(keras.metrics.Metric):
	def __init__(self, threshold=1.0, **kwargs):
		super().__init__(**kwargs) \# handles base args (e.g., dtype) 
		self.threshold = threshold
		self.huber_fn = create_huber(threshold)
		self.total = self.add_weight("total", initializer="zeros") 
		self.count = self.add_weight("count", initializer="zeros")

	def update_state(self, y_true, y_pred, sample_weight=None): 
		metric = self.huber_fn(y_true, y_pred) self.total.assign_add(tf.reduce_sum(metric)) 	
		self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))
	
	def result(self):
		return self.total / self.count

	def get_config(self):
		base_config = super().get_config()
		return {**base_config, "threshold": self.threshold}
\end{lstlisting}

\subsubsection{Custom layers}
You may occasionally want to build an architecture that contains an exotic layer for which TensorFlow does not provide a default implementation. In this case, you will need to create a custom layer. Or sometimes you may simply want to build a very repetitive architecture, containing identical blocks of layers repeated many times, and it would be convenient to treat each block of layers as a single layer.

First, some layers have no weights, such as \cd+keras.layers.Flatten+ or \cd+keras.layers.ReLU+. If you want to create a custom layer without any weights, the simplest option is to write a function and wrap it in a keras.layers.Lambda layer. For example, the following layer will apply the exponential function to its inputs:

\begin{lstlisting}
exponential_layer = keras.layers.Lambda(lambda x: tf.exp(x))
\end{lstlisting}
To build a custom stateful layer (i.e., a layer with weights), you need to create a subclass of the \cd+keras.layers.Layer+ class:
\begin{lstlisting}
class MyDense(keras.layers.Layer):
	def __init__(self, units, activation=None, **kwargs):
		super().__init__(**kwargs)
		self.units = units
		self.activation = keras.activations.get(activation)
		
	def build(self, batch_input_shape): 
		self.kernel = self.add_weight(name="kernel", shape=[batch_input_shape[-1], self.units],initializer="glorot_normal")
         self.bias = self.add_weight(name="bias", shape=[self.units], initializer="zeros") 	
         super().build(batch_input_shape) # must be at the end

	def call(self, X):
		return self.activation(X @ self.kernel + self.bias)

	def compute_output_shape(self, batch_inputshape):
		return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])	

	def get_config(self):
		base_config = super().get_config()
		return {**base_config, "units": self.units, "activation": keras.activations.serialize(self.activation)}
\end{lstlisting}
